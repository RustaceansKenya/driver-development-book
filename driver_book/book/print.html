<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>driver development in Rust</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><li class="part-title">INTRO</li><li class="chapter-item expanded "><a href="intro/intro.html"><strong aria-hidden="true">1.</strong> Intro</a></li><li class="chapter-item expanded "><a href="intro/prerequisites.html"><strong aria-hidden="true">2.</strong> Prerequisites for the Book</a></li><li class="chapter-item expanded affix "><li class="part-title">UNDERSTANDING DRIVERS (theory)</li><li class="chapter-item expanded "><a href="understanding_drivers/understanding_drivers.html"><strong aria-hidden="true">3.</strong> Intro to Drivers</a></li><li class="chapter-item expanded "><a href="understanding_drivers/controlling_the_device_below.html"><strong aria-hidden="true">4.</strong> Role 1: Controlling the device below</a></li><li class="chapter-item expanded "><a href="understanding_drivers/providing_an_interface.html"><strong aria-hidden="true">5.</strong> Role 2: Providing an interface</a></li><li class="chapter-item expanded "><a href="understanding_drivers/types_of_drivers.html"><strong aria-hidden="true">6.</strong> Types of Drivers</a></li><li class="chapter-item expanded affix "><li class="part-title">BARE METAL PROGRAMMING</li><li class="chapter-item expanded "><a href="bare_metal/the_no_std_preface.html"><strong aria-hidden="true">7.</strong> No std preface</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="bare_metal/definition.html"><strong aria-hidden="true">7.1.</strong> Machine Code</a></li><li class="chapter-item expanded "><a href="bare_metal/dependencies.html"><strong aria-hidden="true">7.2.</strong> Dependencies</a></li><li class="chapter-item expanded "><a href="bare_metal/the_std_library.html"><strong aria-hidden="true">7.3.</strong> The Standard Library</a></li><li class="chapter-item expanded "><a href="bare_metal/no_std/the_no_std_intro.html"><strong aria-hidden="true">7.4.</strong> No std</a></li><li class="chapter-item expanded "><a href="bare_metal/no_std/removing_std_lib.html"><strong aria-hidden="true">7.5.</strong> Disabling the Standard Library</a></li><li class="chapter-item expanded "><a href="bare_metal/no_std/pracs_1.html"><strong aria-hidden="true">7.6.</strong> Pracs 1</a></li><li class="chapter-item expanded "><a href="bare_metal/no_std/pracs_2.html"><strong aria-hidden="true">7.7.</strong> Pracs 2</a></li></ol></li><li class="chapter-item expanded "><a href="bare_metal/cross_compilation/cross_compilation.html"><strong aria-hidden="true">8.</strong> Cross-Compilation</a></li><li class="chapter-item expanded "><a href="bare_metal/linking/linking.html"><strong aria-hidden="true">9.</strong> Linking</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="bare_metal/linking/rusty_linkers.html"><strong aria-hidden="true">9.1.</strong> Rusty Linkers</a></li></ol></li><li class="chapter-item expanded "><li class="part-title">THE UART</li><li class="chapter-item expanded "><a href="uart_theory/intro.html"><strong aria-hidden="true">10.</strong> Intro</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="uart_theory/draft_1.html"><strong aria-hidden="true">10.1.</strong> general overview</a></li><li class="chapter-item expanded "><a href="uart_theory/draft_2.html"><strong aria-hidden="true">10.2.</strong> uart registers</a></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">11.</strong> Understanding UART physical Implemetation in the esp32</div></li><li class="chapter-item expanded affix "><li class="part-title">THE UART IMPLEMENTATION (on Qemu and single-threaded)</li><li class="chapter-item expanded "><a href="uart_implementations/on_qemu/intro.html"><strong aria-hidden="true">12.</strong> Intro</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="uart_implementations/on_qemu/setting_things_up.html"><strong aria-hidden="true">12.1.</strong> Setting Things Up</a></li><li class="chapter-item expanded "><a href="uart_implementations/on_qemu/setting_up_the_compiler.html"><strong aria-hidden="true">12.2.</strong> Setting up the compiler</a></li><li class="chapter-item expanded "><a href="uart_implementations/on_qemu/writing_a_bare_metal_rust_executable copy.html"><strong aria-hidden="true">12.3.</strong> No-std recap</a></li><li class="chapter-item expanded "><a href="uart_implementations/on_qemu/setting_up_qemu.html"><strong aria-hidden="true">12.4.</strong> Setting up the Riscv Virtual environment</a></li><li class="chapter-item expanded "><a href="uart_implementations/on_qemu/setting_up_LLD_linker.html"><strong aria-hidden="true">12.5.</strong> Setting up the linker</a></li><li class="chapter-item expanded "><a href="uart_implementations/on_qemu/setting_up_build_automation.html"><strong aria-hidden="true">12.6.</strong> Automating build & run</a></li></ol></li><li class="chapter-item expanded "><a href="uart_implementations/on_qemu/loaders_and_bootloaders/intro.html"><strong aria-hidden="true">13.</strong> Loaders and Bootloaders</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="uart_implementations/on_qemu/loaders_and_bootloaders/bootloader.html"><strong aria-hidden="true">13.1.</strong> The Bootloader</a></li><li class="chapter-item expanded "><div><strong aria-hidden="true">13.2.</strong> tutorial over a naive UART implementation on a Esp32 device</div></li></ol></li><li class="chapter-item expanded "><li class="part-title">THE UART IMPLEMENTATION (less naive, with concurrency in mind)</li><li class="chapter-item expanded "><div><strong aria-hidden="true">14.</strong> Concurrency</div></li><li><ol class="section"><li class="chapter-item expanded "><div><strong aria-hidden="true">14.1.</strong> critical-sections in single-threaded cores</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">14.2.</strong> critical-secions above multi-cores</div></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">15.</strong> tutorial over a naive UART implementation on a Qemu device</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">16.</strong> tutorial over a naive UART implementation on a Esp32 device</div></li><li class="chapter-item expanded affix "><li class="part-title">OTHER STORIES</li><li class="chapter-item expanded "><div><strong aria-hidden="true">17.</strong> Driver Security</div></li><li><ol class="section"><li class="chapter-item expanded "><div><strong aria-hidden="true">17.1.</strong> Common Security Issues in Driver Development</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">17.2.</strong> Rust's Safety Features for Driver Security</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">17.3.</strong> Best Practices for Secure Driver Development</div></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">18.</strong> Case Studies and Examples</div></li><li><ol class="section"><li class="chapter-item expanded "><div><strong aria-hidden="true">18.1.</strong> Real-world Driver Development Examples</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">18.2.</strong> Analyzing an Existing Rust Driver</div></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">19.</strong> Iterative Implementation</div></li><li class="chapter-item expanded affix "><li class="part-title">APPENDIX</li><li class="chapter-item expanded "><a href="notable_crates.html"><strong aria-hidden="true">20.</strong> Notable Crates</a></li><li class="chapter-item expanded "><div><strong aria-hidden="true">21.</strong> Notable Learning Resources</div></li><li class="chapter-item expanded "><a href="misc/notable_core_crates.html"><strong aria-hidden="true">22.</strong> Notable core-crates</a></li><li class="chapter-item expanded "><a href="why_embedded_rust.html"><strong aria-hidden="true">23.</strong> why use Rust?</a></li><li class="chapter-item expanded "><div><strong aria-hidden="true">24.</strong> Out of topic</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="misc/different_std_libs.html"><strong aria-hidden="true">24.1.</strong> different_std_libs</a></li><li class="chapter-item expanded "><a href="misc/the_C_runtime.html"><strong aria-hidden="true">24.2.</strong> the-C-runtime</a></li><li class="chapter-item expanded "><a href="misc/API.html"><strong aria-hidden="true">24.3.</strong> api-definition</a></li><li class="chapter-item expanded "><a href="misc/abi.html"><strong aria-hidden="true">24.4.</strong> abi-definition</a></li><li class="chapter-item expanded "><a href="misc/isa.html"><strong aria-hidden="true">24.5.</strong> isa-definition</a></li><li class="chapter-item expanded "><a href="misc/building_runtime_crates.html"><strong aria-hidden="true">24.6.</strong> Building runtimes</a></li><li class="chapter-item expanded "><a href="misc/panicking.html"><strong aria-hidden="true">24.7.</strong> Panicking</a></li></ol></li><li class="chapter-item expanded "><a href="todo.html"><strong aria-hidden="true">25.</strong> To-do</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">driver development in Rust</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/RustaceansKenya/driver-development-book" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="intro"><a class="header" href="#intro">Intro</a></h1>
<p>This book is on driver development using Rust. You get to procedurally write a UART driver for a RISCV chip called ESP32C3 and a Qemu-riscv-virt board.</p>
<p>It is not a book on embedded-development but it will touch up on some embedded-concepts here and there.</p>
<h2 id="book-phases-topics-flow"><a class="header" href="#book-phases-topics-flow">Book phases, topics, flow.</a></h2>
<p>The book will take you through 5 phases :<br />
<strong>Phase 1</strong>:<br />
You get to build a UART driver for a qemu-riscv virtual board. This will be our first phase because it will take you through the fundamentals without having to deal with the intricacies of handling a physical board or writing flashing algorithms.<br />
This UART driver will NOT be multi_thread-safe.</p>
<p><strong>Phase 2</strong>:<br />
We improve the UART driver using standard abstractions: PAC, HAL and other crates. This phase will try to show devs how to make standard drivers that are more portable.</p>
<p><strong>Phase 3</strong>:<br />
You get to modify the previously built UART driver so that it could run on the esp32 physical board. We set up flashing, debugging, logging and testing on the physical board.</p>
<p>We will not use the standard esp-tools but we will try to modify probe-rs, this is because esp-tools abstract away a lot of details that are important for driver-devs to master. Esp-rs tools are just too good to use... it would be awesome if we tried to write our own flashing algorithms and build or own logging module.</p>
<p>We will however imitate the esp-tools.</p>
<p>The driver produced in this phase will still NOT be multi_thread-safe.</p>
<p><strong>Phase 4</strong>:<br />
We do some brush-up on driver-security and performance testing.</p>
<p><strong>Phase 5</strong>:<br />
We start making our driver to be multi-thread safe. This will be first done in a qemu virtual environment to reduce the complexity. After we have figured our way out of the virtual threads, we will move on to implementing things on the physical board</p>
<h3 id="why-the-uart"><a class="header" href="#why-the-uart">Why the UART?</a></h3>
<p>The UART driver was chosen because it is simple and hard at the same time. Both a beginner and an experienced folk can learn a lot while writing it.<br />
For example, the beginner can write a minimal UART and concentrate on understanding the basics of driver development; No-std development,linking, flashing, logging, abstracting things in a standard way, interrupt and error-handling...<br />
The pseudo_expert on the other hand can write a fully functional concurrent driver while focusing on things like performance optimization,concurrency and parallelism.</p>
<p>A dev can iteratively work on this one project for a long time while improving on it and still manage to find it challenging on each iteration. You keep on improving.</p>
<p>Moreover, the UART is needed in almost all embedded devices that require some form of I/O; making it a necessary topic for driver developers.</p>
<p>The main aim here is to teach, not to create the supreme UART driver ever seen in the multiverse.</p>
<h3 id="what-this-book-is-not"><a class="header" href="#what-this-book-is-not">What this book is NOT</a></h3>
<p>This book does not explain driver development for a particular Operating System or Kernel. Be it Tock, RTOS, Windows or linux. This book assumes that you are building a generic driver for a bare-metal execution environment.</p>
<h3 id="quick-links"><a class="header" href="#quick-links">Quick links</a></h3>
<p>To access the tutorial book, visit : <a href="https://rustaceanskenya.github.io/driver-development-book/">this link</a><br />
To access the source-code, visit <a href="https://github.com/RustaceansKenya/driver-development-book/tree/master/driver_code">this repo's sub-folder</a></p>
<p>This is an open-source book, if you feel like you want to adjust it...feel free to fork it and create a pull-request.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="prerequisites-for-the-book"><a class="header" href="#prerequisites-for-the-book">Prerequisites for the Book</a></h1>
<p>The prerequisites are not strict, you can always learn as you go:</p>
<ul>
<li>Computer architecture knowledge : you should have basic knowledge on things like RAM, ROM, CPU cycle, buses...</li>
<li>Rust knowledge : You don't have to be a generics or atomics guru. You do not need to know concurrency... but it's something you will eventually need to learn in the course of the book. If you are okay with the topics covered before chapter 14 in the Rust book, then you are overqualified for this.</li>
<li>Have an esp32-c3. </li>
<li>Have some interest in driver development.</li>
<li>Have lots of time. Driver development takes time... learning it for the fast time takes even more time. </li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="intro-to-drivers"><a class="header" href="#intro-to-drivers">Intro to Drivers</a></h1>
<p>This chapter is filled with definitions.</p>
<p>And as you all know, there are NO right definitions in the software world. People still debate what 'kernel' means. People are okay using the word 'serverless' apps. What does AI even mean? It's chaos everywhere.</p>
<p>So the definitions used here are constrained in the context of this book.</p>
<h3 id="whats-a-driver"><a class="header" href="#whats-a-driver">What's a driver?</a></h3>
<p>A driver is the <strong>first</strong> piece of software that abstracts the circuitry a physical device. We have used the word <strong>first</strong> because technically... even the browser indirectly abstracts hardware.</p>
<p>So the first piece of software on top of a physical device is called a driver.</p>
<p>A driver typically sits in-between a high-leve program and the physical device.<br />
The high level program could be a kernel in this case. And the physical device could be an SSD disk attached to the motherboard.</p>
<p>The driver has 2 primary functions : </p>
<ol>
<li>Controll the underlying device. (the SSD)</li>
<li>Provide an interface for the kernel/higher-level program to interact with. The interface could contain things like public functions, data_structures and message passing endpoints that somehow manipulate how the driver controls the underlying device...</li>
</ol>
<p>Here is a Bird's eye-view of the driver's ecosystem:<br />
<img src="understanding_drivers/img/birds_eye_view_upper.svg" alt="Alt text" /></p>
<p>Demo : 
<img src="understanding_drivers/img/birds_eye_view.svg" alt="Alt text" /></p>
<p>Let's break down the two main roles of the driver... </p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="role-1--controlling-the-physical-device-below"><a class="header" href="#role-1--controlling-the-physical-device-below">Role 1 : Controlling the Physical device below</a></h1>
<p><strong>TLDR</strong> :<br />
The driver controls the hardware below by either <strong>Direct Register Programming</strong> or <strong>Memory Mapped Programming</strong>. This can be done in Assembly, low-level languages like C/Rust, or a mixture of both.</p>
<p>A physical device is a piece of electronic that does things, for example, an SSD disk stores data. You can read and write to that SSD device.</p>
<p>An SSD is roughly made up of : </p>
<ol>
<li>Storage cells</li>
<li>A small IC or processor that implements the SSD's firmware</li>
<li>The SSD's firmware stored in the SSD's ROM</li>
<li>Exposed registers</li>
</ol>
<p>The only way to interact with the device is through the exposed registers.</p>
<p>To make the device do things, you meaningfully supply electrical signals to the exposed registers. Once the CPU detects signals on the registers, it interprets them as parameters for the functions defined in the firmware. From there, the firmware does its duties.</p>
<p>Here is an extremely over-simplified and incorrect view of the SSD :</p>
<p><img src="understanding_drivers/img/ssd_stub.svg" alt="Alt text" /></p>
<p>Usage :</p>
<ol>
<li>To store data to the SSD...
<ol>
<li>You write an 8-bit address to the address register. This is called the 'destination address': it is the memory address of the place you want to write to in the SSD.</li>
<li>You write the 8-bit data that you wanted to store in the data register. This is called the 'subject data'</li>
<li>You make sure that the read register is not receiving any signal. This gets translated as 'read == false'.</li>
<li>You supply an electric signal to the write register. This electrical signal is translated as 'write == true'.</li>
<li>The SSD processor detects a signal in the 'write' register and immediately does the following : 
<ul>
<li>It passes the 'destination' address and the 'subject data' to the <code>write function</code></li>
<li>It starts executing the &quot;write function&quot; found in the firmware code. </li>
<li>Viollah! The write operation is complete.</li>
</ul>
</li>
</ol>
</li>
</ol>
<h3 id="a-manual-driver"><a class="header" href="#a-manual-driver">A manual driver?</a></h3>
<p>If we had the ssd and a couple of electric wires only, we could store data without using a driver. All we have to do is to supply meaningful electric signals to the registers of the ssd.</p>
<p>For example, to store the number 1 into the address 0x05, we could do this... 
<img src="understanding_drivers/img/ssd_stub_manual_write.svg" alt="Alt text" /></p>
<h3 id="programming"><a class="header" href="#programming">Programming</a></h3>
<p>We are developers, we automate everything... especially when it is unnecessary. Our superpower.<br />
So how do we automate this manual manipulation of SSD registers? How?? Panic everywhere!!</p>
<p><em><strong>Solution 1: Direct Register Programming</strong></em></p>
<p>We attach all the SSD registers DIRECTLY to the CPU. And then write some assembly code to change the values of the attached registers...<br />
This solution gets the job done.</p>
<p>Demo: 
<img src="understanding_drivers/img/ssd_stub_register_programming.svg" alt="Alt text" /></p>
<p><em><strong>Solution 2: Memory Mapped Programming</strong></em><br />
The CPU has a limited number of registers. The RAM exists because of this exact reason.<br />
So instead of directly attaching the SSD registers to the limited CPU registers, we could attach them to the RAM instead.</p>
<p>We could then write some assembly code to manipulate RAM addresses, hence indirectly manipulating the values of the SSD registers. This is called Memory-mapped I/O programming (<strong>mmio programming</strong>).</p>
<p>This is the method that we will stick to because it is more practical.</p>
<p>You could however use Direct Register Programming when building things like pace-makers, nanobots or some divine machine that is highly specialized and requires 100% performance.</p>
<p>Here is a demo of a naive MMIO setup : 
<img src="understanding_drivers/img/ssd_stub_mmio_programming.svg" alt="Alt text" /></p>
<h3 id="summary"><a class="header" href="#summary">Summary</a></h3>
<p>The driver controls the hardware below by either <strong>Direct Register Programming</strong> or <strong>Memory Mapped Programming</strong>. This can be done in Assembly, low-level languages like C/Rust, or a mixture of both.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="role-2-providing-an-interface"><a class="header" href="#role-2-providing-an-interface">Role 2: Providing an Interface</a></h1>
<p>The driver acts as an interface between the physical device and the kernel.<br />
An interface consists of :</p>
<ul>
<li>callable functions exported by the driver</li>
<li>exported structs</li>
<li>exported traits</li>
<li>exported macros</li>
<li>... some glue code or whatever</li>
</ul>
<p>It is up to the programmer to make the Interface to be : </p>
<ol>
<li>Clear and Intuitive</li>
<li>Complete and correct </li>
<li>Simple</li>
<li>Modular (well structured)</li>
<li>Well documented</li>
</ol>
<p>We will cover these concepts in a practical manner while writing our driver. So don't stress about finding the right guide or definition for writing 'the perfect API'. There is no perfect API. You just try your best to fulfill the above 6 vague goals and with time your APIs will get better and better.</p>
<p>Oh... here are the definitions of the above 6 goals.</p>
<ol>
<li>
<p>Clear and Intuitive : the names of the Interface elements should be meaningful. They should be easy to undersand. For example, a function that switches off the device should have a name like <code>switch_off_device</code>. </p>
</li>
<li>
<p>Complete and correct : </p>
<ul>
<li>A complete API is an interface that abstracts ALL the possible functions of the underlying device. Can you imagine an SSD driver that does not provide the <code>read</code> function?</li>
<li>A correct API does not expose functions that are wrong and sometimes produce undefined behavior. </li>
</ul>
</li>
<li>
<p>Simple : Be simple... Dumb things down.</p>
</li>
<li>
<p>Modular : A modular API is structured in such a way that a user can intuitively guess where things have been bundled up. For example, put error-codes in one module, put read functions in onother module... </p>
</li>
<li>
<p>Well documented.</p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="types-of-drivers"><a class="header" href="#types-of-drivers">Types of Drivers</a></h1>
<p>Classifications and fancy words do not matter, we go straight to the list :</p>
<h2 id="drivers-classified-by-the-level-of-how-close-to-the-metal"><a class="header" href="#drivers-classified-by-the-level-of-how-close-to-the-metal">Drivers classified by the level of 'how close to the metal?'</a></h2>
<ol>
<li>
<p><strong>Function drivers</strong> : this drivers implement functions that directly manipulate registers. You could say that this are the OG drivers. </p>
</li>
<li>
<p><strong>Filter drivers/ Processing drivers/ Wrapper drivers</strong>: This drivers take input from the function drivers and process them into palatable input and functions for the kernel. They can be seen as 'adapters' between the function-driver and the kernel. They can even be used to implement additional security features. Point being, their main function is wrapping the function-driver.</p>
</li>
</ol>
<p>Oh look... this 👇🏻 is what we were talking about... thanks windows for your docs.<br />
<img src="understanding_drivers/img/types_of_drivers.png" alt="Alt text" /><br />
This image was borrowed from the <a href="https://learn.microsoft.com/en-us/windows-hardware/drivers/gettingstarted/what-is-a-driver-">Windows Driver development docs</a></p>
<p><strong>Note</strong> : <em>A driver stack</em> is a collection of different drivers that work together to achieve a common goal. For example, you may use many function and filter drivers to control an integrated piece of hardware.<br />
Another example : You may use a couple of filter drivers when porting a function driver to a new kernel environment.</p>
<h2 id="drivers-classified-by-function"><a class="header" href="#drivers-classified-by-function">Drivers classified by function</a></h2>
<ul>
<li>storage drivers : eg ssd drivers</li>
<li>File System Drivers : Drivers above the file system.</li>
<li>system drivers : used in motherboard components instead of peripherals</li>
<li>Input Device Drivers</li>
<li>Network Drivers</li>
<li>Communication drivers</li>
<li>Virtual drivers (Emulators)</li>
<li>This list can be as long as one can imagine... but I hope you get the drift</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="bare-metal-programming"><a class="header" href="#bare-metal-programming">Bare Metal Programming</a></h1>
<p>Bare Metal Programming !!!!!!!!!!🥳🥳🥳🥳 </p>
<p>Welcome to the first cool chapter.</p>
<p>This chapter takes you through the process of writing a program that does not depend on the standard library/crate. A program that can be loaded and ran on any board with a processor and some bit of memory... be it an arduino, an esp or a custom board that you manufactured in your teenage bedroom.</p>
<p><a href="https://os.phil-opp.com/">Philipp Oppermann's blog</a> covered Bare-metal programming very well. Philipp's blog covers the topic across two chapters, you can read them here 👇🏽: </p>
<ul>
<li>Chapter 1 : <a href="https://os.phil-opp.com/freestanding-rust-binary/">A Freestanding Rust Binary</a></li>
<li>Chapter 2 : <a href="https://os.phil-opp.com/minimal-rust-kernel/">A Minimal Rust Kernel</a></li>
</ul>
<p>It would be an <strong>UNDERSTATEMENT</strong> to call those 2 chapters legendary.<br />
Just go give them a read... waste your time well.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="machine-code"><a class="header" href="#machine-code">Machine code</a></h1>
<p>From your Computer architecture class, you learnt that the processor is a bunch of gates cramped up together in a meaningful way. A circuit of some sort.</p>
<p>You also learnt that each processor implements an <a href="bare_metal/../misc/isa.html">ISA (Instruction Set Architecture)</a>.<br />
As long as you can compile high level code into machine code that is within the bounds of the ISA, that CPU will gladly execute your code. You don't even have to follow a certain <a href="bare_metal/../misc/abi.html">ABI</a> in order for that code to run.</p>
<p>The main point here is that : &quot;Machine code that follows a certain ISA can run on any processor that implements that ISA.&quot; This is because the processor is a DIRECT implementation of the ISA specifications.</p>
<p>So the processor that you built in your room can run Rust code. As long as that rust code gets compiled into machine code that follows the ISA specifications of your custom processor.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="dependencies"><a class="header" href="#dependencies">Dependencies</a></h1>
<p>A library refers to a collection of precompiled routines, functions, classes, or modules that can be reused by various programs or applications to perform specific tasks or operations. Libraries are essentially packages of code that provide commonly used functionality, such as mathematical operations, file handling, networking, user interface components, and more.</p>
<p>A dependency, on the other hand, refers to a specific software component or library that a project relies on to function properly.</p>
<p>For example, the hello-world program below uses the <code>time</code> library as a dependency:</p>
<pre><pre class="playground"><code class="language-rust">use time; 

fn main(){
    println!(&quot;Hello world!!!&quot;);
}</code></pre></pre>
<h2 id="default-dependencies"><a class="header" href="#default-dependencies">Default dependencies</a></h2>
<p>By default, all rust programs use the <a href="https://doc.rust-lang.org/std/index.html"><code>std</code> library</a> as a dependency. Even if you write a simple hello-world or an add-library, the contents of the <a href="https://doc.rust-lang.org/std/prelude/index.html"><code>std::prelude</code></a> library get included as part of your code as if you had written it as follows...</p>
<pre><pre class="playground"><code class="language-rust">use std::prelude::*; // this line is usually not there... but theoretically, 
                    // your compiler treats your code as if this line was explicitly declared here

fn main(){
    println!(&quot;Hello world!!!&quot;);
}</code></pre></pre>
<p>So ... what is the standard library? What is a prelude?  </p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-standard-library"><a class="header" href="#the-standard-library">The Standard Library</a></h1>
<p>The standard library is a library like any other... it is just that it contains definitions of things that help in very essential tasks. Tasks that are expected to be found in almost every OS.</p>
<p>For example, it may contain declarations &amp; definitions of <code>file-handling functions</code>, <code>thread-handling functions</code>, <code>String struct definition</code>, ... etc</p>
<p>You can find the documentation of the rust standard library <a href="https://doc.rust-lang.org/std/index.html">here</a>.</p>
<p>Below is a story that explains more about standard libraries (the story does not explain the actual modules of the standard library). </p>
<h1 id="story-time"><a class="header" href="#story-time">Story time</a></h1>
<p>You can skip this page if you already understand ...</p>
<ul>
<li>What the standard library is</li>
<li>Why it exists</li>
<li>The different standards that may be followed</li>
</ul>
<h2 id="posix"><a class="header" href="#posix">Posix</a></h2>
<p>Long ago ... once upon a time (in the 70s-80s), there were a lot of upcoming operating systems. Each operating system had its's own features. For example, some had graphical interfaces, some didn't. Some could run apps using multi-threading capabilities, others didn't. Some had file systems that contained like 100 functions... others had like 10 file-handling functions.</p>
<p>It was chaos everywhere. For example : the <code>open_file()</code> function might have had different names across many operting systems. So if you wrote an app for 3 OSes, you would have re-written your code 3 times just because the <code>open_file</code> function was not universal. 
It was a bad time to be an app developer. You either had to specialize in writing apps for one operating system OR sacrifice your sanity and learn the commands of multiple Operating systems.</p>
<p>To make matters worse... the individual operting systems were improving FAST... so function names were changing, file_handling routines were changing, graphical output commands were changing. CHAOS! EVERYWHERE.</p>
<p>So developers decided that they needed some form of decorum for the sake of their sanity.<br />
They decided to create common rules and definitions on the three topics below : </p>
<ol>
<li>Basic definitions</li>
<li>System interface</li>
<li>Shell and utilities.</li>
</ol>
<p>So what the hell are these three things?</p>
<h3 id="1-basic-definitions"><a class="header" href="#1-basic-definitions">1. Basic definitions</a></h3>
<p>Just as the title says, before the devs made rules, they had to first know that they were speaking the same language. I mean... how can you make rules about something that you don't even have a description for?</p>
<p>They had to define the meaning of words. Eg &quot;What is a <code>process</code>? What is an <code>integer</code>? What is a <code>file</code>? What is a <code>kernel</code> even?<br />
Defining things explicitly reduced confusion. </p>
<p>They had to </p>
<ol>
<li>Agree on the definition of things ie terminology. </li>
<li>Agree on the exact representation of data-types and their behavior. This representation does not have to be the same as the ABI that you are using, you just have to make sure that your kernel interface <em>treats</em> data-types as defined here.</li>
<li>Agree on the common constants : For example error_codes, port numbers of interes ...</li>
</ol>
<h3 id="2-system-interface"><a class="header" href="#2-system-interface">2. System Interface</a></h3>
<p>As earlier mentioned, each kernel had different features and capabilities... some had dozens of advanced and uniquely named file-handling functions while others had like 2 poorly named and unique file-handling functions.</p>
<p>This was a problem. It forced devs to have to re-write apps for each OS.<br />
So the devs sat down and created a list of well-named function signatures... and declared that kernel developers should implement kernels that us those exact signatures. They also explicitly defined the purpose of each of those functions. eg </p>
<pre><code class="language-bash">void _exit(int status); # A function that terminates a process

</code></pre>
<p>You can find the full description of the <code>_exit</code> function <a href="https://pubs.opengroup.org/onlinepubs/9699919799/functions/_exit.html">here</a> and see how explicit the definitions were.</p>
<p>This ensured that all kernels, no matter how different, had a similar interface. Now devs did not need to re-write apps for each OS. They no longer had to learn the interfaces of each OS. They just had to learn ONE interface only.</p>
<p>These set of functions became known as the System interface.<br />
You can view the POSIX system interface <a href="https://pubs.opengroup.org/onlinepubs/9699919799/functions/contents.html">here</a></p>
<h3 id="3-shell-and-its-utilities"><a class="header" href="#3-shell-and-its-utilities">3. Shell and its utilities</a></h3>
<p>The Operating system is more than just a kernel. You need the command line. You may even need a Graphic User Interface like a Desktop.<br />
In the 1980's, shells were the hit. So there were dozens of unique shells, each with their own commands and syntax.</p>
<p>The devs sat down and declared the common commands that had to be implemented by all shells eg <code>ls</code>, <code>mv</code>, <code>grep</code>, <code>cd</code>...</p>
<p>As for the shell syntax... well... I don't know... the devs tried to write a formal syntax. It somehow worked, but people still introduced 
their own variations. (which is good, bash syntax is horrifying... I took years to get good at Rust/JS/C/C++, but I'm sure I'll take my whole life to get comfortable with bash)</p>
<p>This specifications came to be known as the <a href="https://en.wikipedia.org/wiki/POSIX">POSIX standard</a>.</p>
<h2 id="entry-of-the-standard-library"><a class="header" href="#entry-of-the-standard-library">Entry of the standard library</a></h2>
<p>Why is this POSIX story relevant?<br />
Well... because the standard libraries implement parts of the POSIX standard.</p>
<p>For example...</p>
<ol>
<li>The standard library defines the definitions of the functions defined in the POSIX system interface.</li>
<li>The data-types used in the above function definitions follow the data-type representation specified by the POSIX's basic deinitions chapter.</li>
</ol>
<p>Examples of standard libraries that adhere to the POSIX standard include : The C standard library(glibc) and The Rust standard library. They may not strictly adhere to the POSIX specifications but they come close to it.</p>
<h2 id="posix-compliance"><a class="header" href="#posix-compliance">POSIX compliance</a></h2>
<p>If you look at the <a href="https://pubs.opengroup.org/onlinepubs/9699919799/idx/functions.html">list of system functions specified by posix</a>, you might get a heart-attack. That list is LOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOONG.</p>
<p>What if I just wanted to create a small-specialized kernel that does not have a file-system or thread-management? Do I still have to define file-handling functions? Do I still have to define thread-management functions? - NO!, that would be a waste of everyone's time and RAM.</p>
<p>That is why there are many versions of the C standard library. For example, we have <code>glibc</code> and <code>new-libc</code>.<br />
<code>glibc</code> is more POSIX-compliant because it defines more system functions than <code>new-libc</code>.<br />
<code>newlib-c</code> is a C standard library specifically made for <strong>minimalist</strong> kernels. <code>newlib-c</code> defines essential system functions only.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="no-std"><a class="header" href="#no-std">No Std</a></h1>
<p>Most rust programs depend on the standard library by default, including that simple 'hello world' you once wrote. The standard library on the other hand is dependent on the underlying operaring system or execution environment.<br />
For example, the body of <code>std::println!</code> contains lines that call OS-defined functions.</p>
<p>Drivers provide an interface for the OS to use, meaning that the OS depends on drivers... as a result, you have to write the driver code without the help of the OS-dependent Standard Library. This paragraph sounds like a riddle ha ha... but you get the point... to write a driver, you have to forget about help from the typical std library. That std library depends on your driver code... <strong>that std library depends on you</strong>.</p>
<p>When software does not depend on the standard library, it is said to be a bare-metal program. It can just be loaded to memory and the physical CPU will execute it as it is.</p>
<p>Bare metal programming is the art of writing code that assumes zero or almost-zero hosted-environment. A hosted environment typically provides a language runtime + a system interface like POSIX.</p>
<p>We will procedurally create a bare metal program in the next few sub-chapters.</p>
<div style="break-before: page; page-break-before: always;"></div><h3 id="the-standard-library-1"><a class="header" href="#the-standard-library-1">The Standard Library</a></h3>
<p>The standard library is a group of common function declarations that get called by applications that run on top of an OS.<br />
So each OS needs to provide implementations for all those common functions.</p>
<p>For example, the standard library declares the thread_spawn function. Linux OS provides an implementation of that function that is different from the Windows implementation... provided they all do the same thing.</p>
<p>So when you write drivers, you cannot use the standard library. But you can use the <a href="bare_metal/no_std/(https://doc.rust-lang.org/core/)">core-library</a>.</p>
<p>How's that possible? How are we able to use the core library on bare metal?<br />
well...Lib-core functions can be <strong>directly</strong> compiled to assembly and machine code without having to depend on OS-system files. Lib-core is dependency-free.</p>
<p>Losing the std library means you forget about threads, files, heap memory, the network, random numbers, standard output, or any other features requiring OS abstractions or specific hardware. If you need them, you have to implement them yourself. The table below summarizes what you lose...</p>
<div class="table-wrapper"><table><thead><tr><th>feature</th><th>no_std</th><th>std</th></tr></thead><tbody>
<tr><td>heap (dynamic memory)</td><td>*</td><td>✓</td></tr>
<tr><td>collections (Vec, BTreeMap, etc)</td><td>**</td><td>✓</td></tr>
<tr><td>stack overflow protection</td><td>✘</td><td>✓</td></tr>
<tr><td>runs init code before main</td><td>✘</td><td>✓</td></tr>
<tr><td>libstd available</td><td>✘</td><td>✓</td></tr>
<tr><td>libcore available</td><td>✓</td><td>✓</td></tr>
</tbody></table>
</div>
<p>* Only if you use the <code>alloc</code> crate and use a suitable allocator like <a href="https://github.com/rust-embedded/alloc-cortex-m">alloc-cortex-m</a>.</p>
<p>** Only if you use the <code>collections</code> crate and configure a global default allocator.</p>
<p>** HashMap and HashSet are not available due to a lack of a secure random number generator.</p>
<p>You can find lib-core's documentation <a href="bare_metal/no_std/(https://doc.rust-lang.org/core/)">here</a><br />
You can find the standard library's documentation <a href="https://doc.rust-lang.org/std/index.html">here</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="pracs-1"><a class="header" href="#pracs-1">Pracs 1</a></h1>
<p>It is best to do things practically... you get error messages that engrain into you some PTSD.</p>
<h2 id="step-1-disabling-the-std-library"><a class="header" href="#step-1-disabling-the-std-library">Step 1: Disabling the Std library</a></h2>
<p>Go to your terminal and create a new empty project :</p>
<pre><code class="language-bash">cargo new hello_world --bin
</code></pre>
<p>By default, rust programs depend on the standard library. To disable this dependence, you add the 'no_std attribute' to your code. The code however switches to depending on the 'core' crate.</p>
<pre><pre class="playground"><code class="language-rust">#![no_std]

fn main(){
    println!(&quot;Hello world!!&quot;);
}</code></pre></pre>
<p>If you run this code, you get 3 compilation errors. </p>
<ol>
<li>error: cannot find macro <code>println</code> in this scope</li>
<li>error: <code>#[panic_handler]</code> function required, but not found</li>
<li>error: unwinding panics are not supported without std</li>
</ol>
<h2 id="step-2-fixing-the-first-error"><a class="header" href="#step-2-fixing-the-first-error">Step 2: Fixing the first Error</a></h2>
<p>The <a href="https://doc.rust-lang.org/std/macro.println.html">println macro</a> is part of the standard library. That is why it cannot be found in the scope of the 'no_std' crate.<br />
To fix the first error, we remove the println line.</p>
<pre><pre class="playground"><code class="language-rust">#![no_std]

fn main(){
    // println!(&quot;Hello world!!&quot;);
}</code></pre></pre>
<p>Two errors remain...</p>
<h2 id="step-3-fixing-the-second-and-third-error--theory"><a class="header" href="#step-3-fixing-the-second-and-third-error--theory">Step 3: Fixing the second and third error  (theory)</a></h2>
<p>This is going to be a short fix but with a lot of theory behind it.<br />
To solve it, we have to understand the <a href="bare_metal/no_std/(https://doc.rust-lang.org/core/#how-to-use-the-core-library)">core library requirements</a> first. </p>
<p>The core library functions and definitions can get compiled for any target, provided that the target provides definitions of certain linker symbols. The symbols needed are :</p>
<ol>
<li>memcpy, memmove, memset, memcmp, bcmp, strlen. </li>
<li>rust_begin_panic</li>
<li>rust_eh_personality (this is not a symbol, it is actually a <a href="https://os.phil-opp.com/freestanding-rust-binary/#the-eh-personality-language-item">language item</a>)</li>
</ol>
<p>In other words, you can write whatever you want for any supported ISA, as long as you link files that contain the definitions of the above symbols.</p>
<h3 id="1-memcpy-memmove-memset-memcmp-bcmp-and-strlen-symbols"><a class="header" href="#1-memcpy-memmove-memset-memcmp-bcmp-and-strlen-symbols">1. memcpy, memmove, memset, memcmp, bcmp and strlen symbols</a></h3>
<p>These are all symbols that point to memory routines.<br />
You need to provide to the linker the ISA code that implements the above routines.</p>
<p>When you compile Rust code for a specific target architecture (ISA - Instruction Set Architecture), the Rust compiler needs to know how to generate machine code compatible with that architecture. For many common architectures, such as x86, ARM, or MIPS, the Rust toolchain already includes pre-defined implementations of these memory routines. Therefore, if your target architecture is one of these supported ones, you don't need to worry about providing these definitions yourself.</p>
<p>However, if you're targeting a custom architecture or an architecture that isn't directly supported by the Rust toolchain, you'll need to provide implementations for these memory routines. This ensures that the generated machine code will correctly interact with memory according to the specifics of your architecture.</p>
<h3 id="2-the-rust_begin_panic-symbol"><a class="header" href="#2-the-rust_begin_panic-symbol">2. the rust_begin_panic symbol</a></h3>
<p>This symbol is used by Rust's panic mechanism, which is invoked when unrecoverable errors occur during program execution. Implementing this symbol allows the generated code to handle panics correctly.<br />
You could say that THIS symbol references the function that the Rust runtime calls whenever a panic happens.</p>
<p>This means that you have to... </p>
<ol>
<li>Define a function that acts as the overall panic handler. </li>
<li>Put that function in a file</li>
<li>Link that file with your driver code when compiling.</li>
</ol>
<p>For the sake of ergonomics, the cool rust developers provided a 'panic-handler' attribute that you can attach to a divergent function. You do not have to do all the linking vodoo. This has been demonstrated later on... do not worry if this statement did not make sense.</p>
<h3 id="3-the-rust_eh_personality"><a class="header" href="#3-the-rust_eh_personality">3. The rust_eh_personality</a></h3>
<p>When a panic happens, the rust runtime starts unwinding the stack so that it can free the memory of the affected stack variables. This unwinding also ensures that the parent thread catches the panic and maybe deal with it.</p>
<p>Unwinding is awesome... but complicated to implement without the help of the std library. <em>Coughs in soy-dev</em>.</p>
<p>The rust_eh_personality is a language item that defines how the rust runtime behaves if a panic happens : &quot;does it unwind the stack? How does it unwind the stack? Or does it just refuse to unwind the stack and instead just end program execution?</p>
<p>To set this language behaviour, we are faced with two solutions :</p>
<ol>
<li>Tell rust that it should not unwind the stack and instead, it should just abort the entire program.</li>
<li>Tell rust that it should unwind the stack... and then offer it a pointer to a function definition that clearly implements the unwinding process. (we are soy-devs, this option is completely and utterly off the table!!)</li>
</ol>
<h2 id="step-3something-fixing-the-third-error"><a class="header" href="#step-3something-fixing-the-third-error">Step 3.something: Fixing the third Error</a></h2>
<p>The remaining errors were ...</p>
<pre><code class="language-bash">error: `#[panic_handler]` function required, but not found

error: language item required, but not found: `eh_personality`
  |
  = note: this can occur when a binary crate with `#![no_std]` is compiled for a target where `eh_personality` is defined in the standard library
  = help: you may be able to compile for a target that doesn't need `eh_personality`, specify a target with `--target` or in `.cargo/config`

error: could not compile `playground` (bin &quot;playground&quot;) due to 2 previous errors
</code></pre>
<p>This is our third error...</p>
<pre><code class="language-bash">error: `#[panic_handler]` function required, but not found
</code></pre>
<p>This is our fourth...</p>
<pre><code class="language-bash">error: language item required, but not found: `eh_personality`
</code></pre>
<p>Just like you guessed, the third error occured because the 'rust_begin_panic symbol' has not been defined. We solve this by pinning a '#[panic_handler]' attribute on a divergent function that takes 'panicInfo' as its input. This has been demonstrated below. A divergent function is a function that never returns.</p>
<pre><pre class="playground"><code class="language-rust">#![no_std]

use core::panic::PanicInfo;


#[panic_handler]
// you can name this function any name...it does not matter. eg the_voice_breaker_the_original_copy_the_one_and_only_HIM
// The function takes in a reference to the panic Info. 
// Kid, go read the docs in core::panic module. You're a super soldier.  
fn default_panic_handler(_info: &amp;PanicInfo) -&gt; !{
    loop {  
        // function does nothing for now, but this is where you write your magic //
        // This is where you typically call an exception handler, or call code that logs the error messages before aborting the program
        // The function never returns, this is an endless loop... it is a divergent function
      }
}


fn main(){
    // println!(&quot;Hello world!!&quot;);
}</code></pre></pre>
<p>Would you look at that... if you compile this program, you'll notice that the third compilation error is f* gone!!! Hapa ni wapi!? Mwalimu wa maths!?</p>
<p>[undone : remove this before you publish]</p>
<h2 id="step-4-fixing-the-fourth-error"><a class="header" href="#step-4-fixing-the-fourth-error">Step 4: Fixing the Fourth Error</a></h2>
<p>The fourth error states that the 'eh_personality' language item is missing.<br />
But it is missing because we have not declared it anywhere... we havent even defined a stack unwinding function. So we just configure our program to never unwind the stack, that way... defining the 'eh_personality' becomes optional.</p>
<p>We do this by adding the following lines in the cargo.toml file : </p>
<pre><code class="language-toml"># this is the cargo.toml file
[package]
name = &quot;driver_code&quot;
version = &quot;0.1.0&quot;
edition = &quot;2021&quot;

[profile.release]
panic = &quot;abort&quot; # if the program panics, just abort. Do not try to unwind the stack

[profile.dev]
panic = &quot;abort&quot; # if the program panics, just abort. Do not try to unwind the stack
</code></pre>
<p>Now ... drum-roll... time to compile our program without any errors....</p>
<p>But then ... out of no-where, we get a new diferent error ... </p>
<pre><code class="language-bash">error: using `fn main` requires the standard library
  |
  = help: use `#![no_main]` to bypass the Rust generated entrypoint and declare a platform specific entrypoint yourself, usually with `#[no_mangle]`
</code></pre>
<p>Aahh errors... headaches...<br />
But at least it is a new error. 🤌🏼🥹<br />
It's a new error guys!! 🥳💪🏼😎</p>
<!-- [undone] -->
<!-- - crt0 functions
- crt0 implemetations
- elf board support? How is it implemented?
- triple-targets
- what does target add command actually do and why
- Target support
- Adding custom targets



- THe boot process
- THe esp32 boot process
- Loaders : BIOS, UEFI, U-Boot SPL, CoreBoot
- Runtimes : UEFI, ATF(ARM TRUSTED FIRMWARE)
- BootLoaders : Uboot, Grub, Linux Boot
- firmware standards in the RISCV ISA
- Open SBI
- System V ABI

Bios :
- firmware that sets up environment fit to run a kernel on. It does the following
  - does a power-on-self-test
  - loads the boot loader to memory. The bootloader then loads the Kernel
- Source Material : https://riscv.org/wp-content/uploads/2019/12/Summit_bootflow.pdf
- Multiboot standard -->
<!-- [undone: more info needed on these memory routines specifies as libcore requirements and their integration] -->
<div style="break-before: page; page-break-before: always;"></div><h1 id="pracs-2"><a class="header" href="#pracs-2">Pracs 2</a></h1>
<p>At the end of the last sub-chapter, we got the following error : </p>
<pre><code class="language-bash">error: using `fn main` requires the standard library
  |
  = help: use `#![no_main]` to bypass the Rust generated entrypoint and declare a platform specific entrypoint yourself, usually with `#[no_mangle]`
</code></pre>
<p>Before we solve it, we need to cover some theory... </p>
<h2 id="rust-init-code-theory"><a class="header" href="#rust-init-code-theory">Rust init code theory</a></h2>
<p>'init code' is the code that gets called before the 'main()' function is called. 'init code' is not a standard name, it is just an informal name, but I hope you catch the meaning here. It is the code that gets executed in preparation for the main function.</p>
<p><img src="bare_metal/no_std/img/init_code_birds_view.svg" alt="Alt text" /></p>
<p>To understand 'init code', we need to understand how programs get loaded. Here we go...</p>
<h3 id="understanding-program-flow-machine-boot"><a class="header" href="#understanding-program-flow-machine-boot">Understanding program flow; Machine boot.</a></h3>
<p>When the power button of a machine(laptop) is pressed, the following events occur (an inaccurate description): </p>
<ol>
<li>
<p>Power flows into the processor. The processor immediately begins the fetch-execute cycle. Exept that the first fetch occurs from the ROM where the firmware is.</p>
</li>
<li>
<p>So in short, the firmware starts getting executed. The firmware performs a power-on-self test. </p>
</li>
<li>
<p>The firmware then makes the CPU to start fetching instructions from the ROM section that contains the <strong>loader</strong>. The loader is a program that can copy a program from memory and paste it in the RAM in an orderly way. By orderly way I mean ... it sets up the stack, adds some stack-control code to the RAM, it then loads up the different sections of the program. If the program has <a href="https://www.youtube.com/watch?v=lWVQsld8hMI">overlays</a> - it loads up the code that implements overlay control too.<br />
Essentially, the loader can paste a program on the RAM in a <strong>complete</strong> way.</p>
</li>
<li>
<p>The loader loads the Bootloader onto the RAM.</p>
</li>
<li>
<p>The loader then makes the CPU to point to the RAM section where the Bootloader is situated.</p>
</li>
<li>
<p>The Bootloader on the other hand starts setting up the RAM sections in preparation for loading the kernel.</p>
</li>
<li>
<p>The Bootloader then copies the kernel onto the RAM and makes the CPU pointer to point to the entry point of the kernel. An entry-point is the memory address of the first instruction for any program.</p>
</li>
<li>
<p>The kernel then loads the apps that run on top of it...</p>
</li>
</ol>
<p><strong>Why are we discussing all these?</strong><br />
To show that programs get executed ONLY because : </p>
<ol>
<li>
<p>They were loaded onto either the ROM or the RAM in a <strong>complete</strong> way. The stacks control, overlay-control and other control code routines were also copied onto the RAM together with the actual subject program. The action of copying 'control' code onto the RAM is part of <strong>Setting up the environment</strong> before program execution starts.</p>
</li>
<li>
<p>The CPU's instruction pointer happened to point to the <strong>entry point</strong> of the loaded program. An entry-point is the memory address of the first instruction for a certain program.</p>
</li>
</ol>
<h3 id="loading-a-rust-program"><a class="header" href="#loading-a-rust-program">Loading a Rust Program</a></h3>
<p>From the previous discussion, it became clear that to properly load a program, you have to setup its environment and identify its entrypoint.</p>
<p>A typical Rust program that depends on the std library depends on a program called 'crt0' to setup its initial environment. 'crt0' is sometimes called 'the C runtime Zero'. The 'crt0' then transfers control to the 'Rust-runtime'. The rust-runtime does its thing and then it finally calls the usual 'main' function.</p>
<p><img src="bare_metal/no_std/img/init_code_level_2.png" alt="Alt text" /><br />
This is the <strong>normal entry point chain</strong>. ☝🏼</p>
<h3 id="crt0-c-runtime"><a class="header" href="#crt0-c-runtime">CRT0 (C runtime)</a></h3>
<p>So what does the C runtime actually do?<br />
What does setting up the environment mean?<br />
What does runtime support mean?</p>
<p>Read about it <a href="bare_metal/no_std//src/misc/the_C_runtime.html">here</a></p>
<h3 id="the-rust-runtime"><a class="header" href="#the-rust-runtime">The Rust Runtime</a></h3>
<p>The entry-point of the Rust runtime is marked by the <strong>'start' language item</strong>.<br />
Rust only has a very minimal runtime, which takes care of some small things such as setting up stack overflow guards or printing a backtrace on panic. The runtime then finally calls the main function.</p>
<h2 id="fixing-the-error"><a class="header" href="#fixing-the-error">Fixing the Error</a></h2>
<p>To save you some scrolling time, here is the error we are trying to fix.</p>
<pre><code class="language-bash">error: using `fn main` requires the standard library
  |
  = help: use `#![no_main]` to bypass the Rust generated entrypoint and declare a platform specific entrypoint yourself, usually with `#[no_mangle]`
</code></pre>
<p>This error occurs because we have not specified the entrypoint chain of our program.<br />
If we had used the std library, the default entry-point chain could have been chosen automatically ie the entry point could have been assumed to be the 'start' symbol that directly references the Rust runtime entrypoint.</p>
<p>To tell the Rust compiler that we don’t want to use the normal entry point chain, we add the '#![no_main]' attribute. Here's a demo : </p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[no_std]
#[no_main]

use core::panic::PanicInfo;

#[panic_handler]
fn default_panic_handler(_info: &amp;PanicInfo) -&gt; !{
    loop { /* magic goes here */ }
}

// main has just been trashed... coz... why not? It's pointless
<span class="boring">}</span></code></pre></pre>
<p>But when we compile this, we get a linking error, something like this ...</p>
<pre><code class="language-bash">error: linking with `cc` failed: exit status: 1
  |
  # some lines have been hidden here for the sake of presentability...   
<span class="boring">  = note: LC_ALL=&quot;C&quot; PATH=&quot;/home/k/.rustup/toolchains/nightly-x86_64-unknown-linux-gnu/lib/rustlib/x86_64-unknown-linux-gnu/bin:/home/k/.cargo/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin&quot; VSLANG=&quot;1033&quot; &quot;cc&quot; &quot;-m64&quot; &quot;/tmp/rustcWMxOew/symbols.o&quot; &quot;/home/k/ME/Repos/embedded_tunnel/driver-development-book/driver_code/target/debug/deps/driver_code-4c11dfa3f10db3d0.f20457jvl65bh2w.rcgu.o&quot; &quot;-Wl,--as-needed&quot; &quot;-L&quot; &quot;/home/k/ME/Repos/embedded_tunnel/driver-development-book/driver_code/target/debug/deps&quot; &quot;-L&quot; &quot;/home/k/.rustup/toolchains/nightly-x86_64-unknown-linux-gnu/lib/rustlib/x86_64-unknown-linux-gnu/lib&quot; &quot;-Wl,-Bstatic&quot; &quot;/home/k/.rustup/toolchains/nightly-x86_64-unknown-linux-gnu/lib/rustlib/x86_64-unknown-linux-gnu/lib/librustc_std_workspace_core-9686387289eaa322.rlib&quot; &quot;/home/k/.rustup/toolchains/nightly-x86_64-unknown-linux-gnu/lib/rustlib/x86_64-unknown-linux-gnu/lib/libcore-632ae0f28c5e55ff.rlib&quot; &quot;/home/k/.rustup/toolchains/nightly-x86_64-unknown-linux-gnu/lib/rustlib/x86_64-unknown-linux-gnu/lib/libcompiler_builtins-3166674eacfcf914.rlib&quot; &quot;-Wl,-Bdynamic&quot; &quot;-Wl,--eh-frame-hdr&quot; &quot;-Wl,-z,noexecstack&quot; &quot;-L&quot; &quot;/home/k/.rustup/toolchains/nightly-x86_64-unknown-linux-gnu/lib/rustlib/x86_64-unknown-linux-gnu/lib&quot; &quot;-o&quot; &quot;/home/k/ME/Repos/embedded_tunnel/driver-development-book/driver_code/target/debug/deps/driver_code-4c11dfa3f10db3d0&quot; &quot;-Wl,--gc-sections&quot; &quot;-pie&quot; &quot;-Wl,-z,relro,-z,now&quot; &quot;-nodefaultlibs&quot;
</span>  = note: /usr/bin/ld: /usr/lib/gcc/x86_64-linux-gnu/11/../../../x86_64-linux-gnu/Scrt1.o: in function `_start':
          (.text+0x1b): undefined reference to `main'
          /usr/bin/ld: (.text+0x21): undefined reference to `__libc_start_main'
          collect2: error: ld returned 1 exit status
          
  = note: some `extern` functions couldn't be found; some native libraries may need to be installed or have their path specified
  = note: use the `-l` flag to specify native libraries to link
  = note: use the `cargo:rustc-link-lib` directive to specify the native libraries to link with Cargo (see https://doc.rust-lang.org/cargo/reference/build-scripts.html#cargorustc-link-libkindname)
</code></pre>
<p>This error occurs because the toolchain thinks that we are compiling for our host machine... which in this case happens to be a x86_64-unknown-linux-gnu machine.</p>
<p>To fix this error, we execute one of the following solutions :</p>
<ol>
<li>Specify a cargo-build for a triple target that has 'none' in its OS description. eg <code>riscv32i-unknown-none-elf</code>. This is the easier of the two solutions, and it is the most flexible.</li>
<li>Supply a new linker script that defines our custom entry-point and section layout. If this method is used, the build process will still treat the host's triple-target as the compilation target.</li>
</ol>
<p>If the above 2 paragraphs made complete sense to you, and you were even able to implement them, skip to the <a href="bare_metal/no_std/">Debugging chapter</a> <!-- undone: provide link --></p>
<p>If they did not make sense, then you got some reading to do in the next immediate chapters... <code>Cross compilation and linking</code>.<br />
Don't worry, we will get to a point where our bare-metal code will run without a hitch... but it's a long way to go. And its fun. Rainbows, uniorns and excalibars everywhere!!</p>
<!-- undone : explain the C runtime in more detail -->
<div style="break-before: page; page-break-before: always;"></div><h1 id="cross-compilation"><a class="header" href="#cross-compilation">Cross-Compilation</a></h1>
<h2 id="normal-compilation"><a class="header" href="#normal-compilation">Normal Compilation</a></h2>
<p><strong>Compilation</strong> is the process of converting source code into machine code. For example, converting hello-world to machine code for either a x86 CPU or a Riscv Chip.</p>
<p>The compilation process for a single file roughly looks like this ...<br />
<img src="bare_metal/cross_compilation/img/compilation.png" alt="Alt text" /></p>
<p>When multiple files need to get compiled together, the linker gets introduced : 
<img src="bare_metal/cross_compilation/img/compilation_with_linking.png" alt="Alt text" /></p>
<h2 id="target"><a class="header" href="#target">Target</a></h2>
<p>If we are compiling program <code>x</code> to run on machine <code>y</code>, then machine <code>y</code> is typically referred to as the <code>Target</code>.</p>
<p>If we compile the hello-world for different targets, we may end up with object files that are completely different from each other in terms of file format and file content.<br />
This is because the format and contents of the object file are majorly affected by the following factors : </p>
<ol>
<li>The CPU Architecture of the target</li>
<li>The Vendor-specific implementations on both the software and hardware of the target machine.</li>
<li>The <strong>Execution environment</strong> on which the compiled program is supposed to run on. In most cases the Execution environment is usually the OS.</li>
<li>The <strong>ABI</strong> of the execution environment OR the object file format that is loadable in the execution environment. </li>
</ol>
<p>To find out how these 4 factors affect the object file, read <a href="bare_metal/cross_compilation//src/misc/target_factors.html">here</a>.</p>
<p>So people started describing targets based on the state of the above 4 factors. For example :</p>
<p><strong>Target x86_64-unknown-linux-gnu</strong> means that the target machine contains a x86 CPU, the vendor is unknown and inconsequential, the execution environment is an Operating system called Linux, the execution environment can interact with object files ONLY if they follow the GNU-ABI specification.</p>
<p><strong>Target riscv32-unknown-none-elf</strong> means that the target machine contains a Riscv32 CPU, the vendor is unknown and inconsequential, the execution environment is nothing but bare metal, the execution environment can interact with object files ONLY if they follow the elf specification.</p>
<p>People usually call this target specifications <strong>triple targets</strong>...<br />
Don't let the name fool you, some names contain 2 parameters, others 4 ... others 5.</p>
<p>The 'software world' has a 'naming' problem...once you notice it, you see it everywhere. For example, what is a toolchain? Is it a combination of the compiler, linker and assembler? Or do we throw in the debugger? or maybe even the IDE? What is an IDE?? Is a text Editor with plugins an IDE?? You see? Madness everywhere!!</p>
<h3 id="why-are-triple-target-definitions-important"><a class="header" href="#why-are-triple-target-definitions-important">Why are triple-target definitions important?</a></h3>
<p>Because they help you in choosing and configuring your compiler, assembler and linker.</p>
<p>For example, if you were planning to compile program <code>x</code> for a <code>x86_64-unknown-linux-gnu</code> target....</p>
<ol>
<li>You would look for a x86_64 compiler, and install it.</li>
<li>You would look for a x86_64 assembler, and install it. </li>
<li>You would then look for essential Linux system files that could be linked to your program. </li>
<li>You would look for a Linux implementation of the standard library</li>
<li>You would look for a linker that can output GNU-ABI-compliant object files</li>
<li>You would then configure all these tools and libraries to work together.</li>
</ol>
<p>This is a lot of work and stress. But rust has a solution to this.</p>
<h3 id="enter-target-specification"><a class="header" href="#enter-target-specification">Enter target specification</a></h3>
<p>The default Rust compiler is based on LLVM.<br />
So it is modular, it has a back-end and a fron-end.</p>
<p>You can make the compiler to compile for a specific target by simply running the command : </p>
<pre><code class="language-bash"># install the pre-configured back-end, there is no need for you to perform the 6 steps mentioned above
# This command does all of them... or rather, it modifies your already existing LLVM toolchain  
rustup target add x86_64-unknown-linux-gnu 

# cross-compile for any target whose backend has already been added
cargo build hello-world --target=x86_64-unknown-linux-gnu  
</code></pre>
<h3 id="cross-compilation-1"><a class="header" href="#cross-compilation-1">Cross-compilation</a></h3>
<p><em>The host machine</em> is the machine on which you develop and compile your software.<br />
<em>The target machine</em> is the machine that runs the compiled sotware.</p>
<p>Cross-compilation is the act of compiling a program for a target machine whose triple-target specification is different from the triple-target specification of the host machine.</p>
<h3 id="making-cross-compilation-easier-with-cargo"><a class="header" href="#making-cross-compilation-easier-with-cargo">Making cross-compilation easier with cargo</a></h3>
<p>Example case :<br />
We are compiling a program on a <code>x86_64-unknown-linux-gnu</code> machine. We intend to run the program on a <code>riscv32-unknown-none-elf</code> machine.</p>
<p>We could use the command-line like this... </p>
<pre><code class="language-bash">cargo build --target=riscv32-unknown-none-elf  
</code></pre>
<p>But this would require us to repeat a lengthy comand each time. To make work easier, we could instruct cargo to always compile for a certain triple-target within our cargo project.<br />
This is achieved by modifying the .cargo/config.toml file</p>
<pre><code class="language-bash"># This is the .cargo/config.toml file

[build]
target = riscv32-unknown-none-elf
</code></pre>
<p>So each time you want to build the project, you run the usual command ...</p>
<pre><code class="language-bash">cargo build
</code></pre>
<p>Cargo is an awesome tool, learn more about it in the <a href="https://doc.rust-lang.org/cargo/">Cargo Book</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="linking"><a class="header" href="#linking">Linking</a></h1>
<p>Linking is a VERY fundamental topic.</p>
<p>It is best to learn it <strong>slowly</strong> and <strong>in full</strong> from the <a href="bare_metal/linking/linking.html#note-worthy-docs">docs</a>.<br />
For this reason, this book will not spoil or water-down the purity of the <a href="bare_metal/linking/linking.html#note-worthy-docs">linking docs</a>.</p>
<p>This book will however :</p>
<ul>
<li>Briefly explain LLD linker usage in Rust targets. </li>
<li>Demonstrate how to fix the no-std linking error encountered in the previous chapter </li>
<li>Demonstrate how to build a full linker script for the Esp32c3 board. (found in a much later chapter)</li>
</ul>
<!-- undone: specify the exact chapter -->
<h3 id="note-worthy-docs"><a class="header" href="#note-worthy-docs">Note-worthy docs</a></h3>
<ol>
<li>Start with this <a href="https://www.youtube.com/watch?v=cJDRShqtTbk">3-minute video</a> demonstrating the role of the linker from a high level.</li>
<li>Then move to this <a href="https://users.informatik.haw-hamburg.de/~krabat/FH-Labor/gnupro/5_GNUPro_Utilities/c_Using_LD/ldLinker_scripts.html">doc</a>. It is gentle, covers the basics and its short.</li>
<li>And finally finish it with this <a href="https://sourceware.org/binutils/docs/ld/Scripts.html">more detailed docs</a>. The two most important pages there are on <a href="https://sourceware.org/binutils/docs/ld/MEMORY.html">memory description</a> and <a href="https://sourceware.org/binutils/docs/ld/REGION_005fALIAS.html">memory abstraction</a>.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rusty-linkers"><a class="header" href="#rusty-linkers">Rusty Linkers</a></h1>
<p>This chapter assumes that you have understood the <a href="bare_metal/linking/../linking/linking.html#note-worthy-docs">LD docs</a></p>
<p>There are many linkers in existence. However the two dominant linkers are :</p>
<ol>
<li>The <a href="https://ftp.gnu.org/old-gnu/Manuals/ld-2.9.1/html_mono/ld.html">LD linker</a> (also called the GNU linker)</li>
<li>The <a href="https://lld.llvm.org/">LLD linker</a> (also called the LLVM linker)</li>
</ol>
<p>The Rust toolchain is a modification of the LLVM toolchain, so it uses the LLVM linker by default. You can however configure it to use the GNU linker with the help of Cargo.</p>
<h2 id="subtle-but-important-differences-between-ld-and-lld"><a class="header" href="#subtle-but-important-differences-between-ld-and-lld">Subtle but important differences between LD and LLD.</a></h2>
<h3 id="1-automatic-linker-script-generation"><a class="header" href="#1-automatic-linker-script-generation">1. Automatic linker-script generation.</a></h3>
<p>The ld linker ALWAYS requires a manually-defined linker script to function. The LLD (the LLD linker) doesn't always use a manually-defined linker script like LD (the GNU linker).</p>
<p>In many cases, LLD can automatically generate linker scripts internally based on the target architecture, format, and other parameters specified during the linking process. This means that LLD can handle the linking process without requiring an explicit linker script provided by the user.</p>
<p>However, LLD does provide options to allow users to specify custom linker scripts if needed. Users can pass a custom linker script to LLD using command-line options or configuration files, similar to how it's done with LD. This gives users flexibility in defining the linking behavior and organizing the output binary according to their specific requirements.</p>
<h3 id="2-cross-linking-and-the-existence-of-flavours"><a class="header" href="#2-cross-linking-and-the-existence-of-flavours">2. Cross linking and the existence of flavours</a></h3>
<p>The ld linker is a monolith. There is only one ld linker. If you want to compile something into an elf, you supply the linker with an elf-generating linker script. If you need a wasm binary file, you supply it with a corresponding linker script.<br />
This may seem simple at first, but writing a correct linker script is usually not an easy task. To solve this problem, the LLVM linker implemented the concept of <em>ports</em> AND <em>flavours</em>.</p>
<p>The LLVM linker is not a monolith, it is made up of different specialized linkers within itself. These sub-linkers are called flavours.<br />
The flavours are linkers that are specialized in producing object files for supported targets. For example, Let's say you want to produce a unix elf file, instead of writing a complex &amp; erronous linker script, you use the LD.LLD linker flavour and it will automatically generate an internal script for you. This is what makes LLD a cross-linker by default.</p>
<p>There are currently 4 lld flavours : </p>
<ol>
<li>LD.LLD (unix) : specializes in generating object files and executables for Unix-like operating systems, such as Linux and FreeBSD. It supports formats like ELF (Executable and Linkable Format) and handles symbol resolution, linking libraries, and generating debug information specific to Unix environments.</li>
<li>ld64.lld (macOS) : secializes in producing object files and executables for macOS and other Apple platforms. It supports the Mach-O (Mach Object) file format used on macOS</li>
<li>lld-link (Windows) : specializes in generating object files and executables for Windows-based systems. It supports the PE (Portable Executable) file format used on Windows, handles symbol resolution, and integrates with Windows-specific tools and libraries for linking applications and generating executables compatible with the Windows environment.</li>
<li>wasm-ld (WebAssembly) : This flavour is a work in progress. It specializes in producing WebAssembly (Wasm) modules and executables that follow wasm specifications.</li>
</ol>
<h2 id="implications-of-those-subtle-differences"><a class="header" href="#implications-of-those-subtle-differences">Implications of those subtle differences</a></h2>
<ol>
<li>Declaring linker scripts is optional.</li>
<li>Adding a target using the <code>rustup target add</code> literally adds a LLVM back-end that includes an LLD-flavour configured for the subject target. Declaring linker scripts is optional.</li>
</ol>
<p>To view the defult lld flavour of a supported target, run the following command :</p>
<pre><code class="language-bash"># Replace `riscv32i-unknown-none-elf` with a target of your liking
rustc -Z unstable-options --target riscv32i-unknown-none-elf --print target-spec-json
</code></pre>
<p>Feedback : </p>
<pre><code class="language-bash">{
  &quot;arch&quot;: &quot;riscv32&quot;,
  &quot;atomic-cas&quot;: false,
  &quot;cpu&quot;: &quot;generic-rv32&quot;,
  &quot;crt-objects-fallback&quot;: &quot;false&quot;,
  &quot;data-layout&quot;: &quot;e-m:e-p:32:32-i64:64-n32-S128&quot;,
  &quot;eh-frame-header&quot;: false,
  &quot;emit-debug-gdb-scripts&quot;: false,
  &quot;features&quot;: &quot;+forced-atomics&quot;,
  &quot;is-builtin&quot;: true,
  &quot;linker&quot;: &quot;rust-lld&quot;,  # HERE is the linker name... it could have been something like ld
  &quot;linker-flavor&quot;: &quot;gnu-lld&quot;,  # HERE is the linker Flavour
  &quot;llvm-target&quot;: &quot;riscv32&quot;,
  &quot;max-atomic-width&quot;: 32,
  &quot;panic-strategy&quot;: &quot;abort&quot;,
  &quot;relocation-model&quot;: &quot;static&quot;,
  &quot;target-pointer-width&quot;: &quot;32&quot;
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-uart"><a class="header" href="#the-uart">The UART</a></h1>
<p>This book is about building a UART driver. So of course we <em>have</em> to have  chapter that explains :</p>
<ul>
<li>what the UART is</li>
<li>How the UART works</li>
<li>Its uses</li>
<li>Protocols involved</li>
<li>UART registers</li>
<li>insert many other buzz-sentences here</li>
</ul>
<p>This chapter covers the theory about the UART itself.<br />
Before we build a driver for any piece of hardware, we have to understand that piece of hardware first.<br />
So here goes...</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="general-overview"><a class="header" href="#general-overview">General Overview</a></h1>
<h2 id="what-is-the-uart"><a class="header" href="#what-is-the-uart">What is the UART?</a></h2>
<p>Before tackling the meaning of UART, let's get some acronyms out of the way.</p>
<ul>
<li>UART stands for <code>Universal Asynchronous Receiver/Transmitter</code>.</li>
<li><em>Tx</em> stands for <code>Transmitter</code>.</li>
<li><em>Rx</em> stands for <code>Receiver</code>.</li>
</ul>
<p>We're done with the acronymns, now we are on the same jargon wavelength.</p>
<p>The UART is an integrated circuit that takes in parallel data from one end and outputs serial data on the other end. It also receives serial data from one end and outputs parallel data on the other end.<br />
So you can say that it is a <em>parallel-to-serial converter with a few extra steps</em>.</p>
<p>If you connect two UARTs as seen below, you achieve serial communication between two devices that have parallel data buses.</p>
<p><img src="uart_theory/img/uart_connection.png" alt="Alt text" /></p>
<p><strong>What does asynchronous mean in this case?</strong><br />
&quot;Asynchronous&quot; refers to the method by which data is transmitted and received between two independent devices without requiring a shared clock signal between the transmitting and receiving devices.<br />
Instead of using a clock to synchronize the rate at rate at which bits are exchanged, the two communicating devices agree on the data-packet format and the rate of transmitting the bits of that data-packet.</p>
<p>The rate at which the bits of the data-packet are transmitted is referred to as <code>baud rate</code> in this context.</p>
<h3 id="so-is-uart-a-serial-communication-protocol"><a class="header" href="#so-is-uart-a-serial-communication-protocol">So is UART a serial-communication protocol?</a></h3>
<p>Well... The UART is not a communication protocol itself but rather a hardware component or module that facilitates serial communication between devices. You could say that it is circuitry that serves as the underlying hardware mechanism for implementing various communication protocols such as RS-232, RS-485, MIDI, and others</p>
<p>Confusing... right? ha ha.</p>
<p>UART == circuit.<br />
UART != protocol.<br />
You can implement asynchronous protocols using a UART circuitry. </p>
<h2 id="how-the-uarts-work"><a class="header" href="#how-the-uarts-work">How the UARTs work.</a></h2>
<p>In UART communication, two UARTs communicate directly with each other. The transmitting UART converts parallel data from a controlling device like a CPU into serial form, transmits it in serial to the receiving UART, which then converts the serial data back into parallel data for the receiving device.<br />
Only two wires are needed to transmit data between two UARTs. Data flows from the Tx pin of the transmitting UART to the Rx pin of the receiving UART:</p>
<p><img src="uart_theory/img/comms_between_two_UARTs.png" alt="Alt text" /></p>
<p>UARTs transmit data asynchronously, which means there is no clock signal to synchronize the output of bits from the transmitting UART to the sampling of bits by the receiving UART. Instead of a clock signal, the transmitting UART adds start and stop bits to the data packet being transferred. These bits define the beginning and end of the data packet so the receiving UART knows when to start reading the bits.</p>
<p>When the receiving UART detects a start bit, it starts to read the incoming bits at a specific frequency known as the baud rate (bits per second). Both UARTs must operate at about the same baud rate. The baud rate between the transmitting and receiving UARTs can only differ by about 10% before the timing of bits gets too far off.</p>
<p>So before any data transfer actually happens, the two UARTs must agree on : </p>
<ol>
<li>The Data packet format</li>
<li>The Baud rate (bps)</li>
</ol>
<p><strong>Example Case :</strong></p>
<p><img src="uart_theory/img/uart_connection.png" alt="Alt text" /></p>
<p>The UART that is going to transmit data receives the data from a data bus. The data bus is used to send data to the UART by another device like a CPU, memory, or microcontroller. Data is transferred from the data bus to the transmitting UART in parallel form.<br />
After the transmitting UART gets the parallel data from the data bus, it adds a start bit, a parity bit, and a stop bit, creating the data packet.<br />
Next, the data packet is output serially, bit by bit at the Tx pin. The receiving UART reads the data packet bit by bit at its Rx pin. The receiving UART then converts the data back into parallel form and removes the start bit, parity bit, and stop bits. Finally, the receiving UART transfers the data packet in parallel to the data bus on the receiving end.</p>
<p><strong>If the communication between the two is asynchronous, how do they agree with each other in the first place?</strong></p>
<ol>
<li>
<p><strong>Manual Configuration</strong>: In many systems, the baud rate is manually configured by the user or system designer. This involves setting the baud rate to a specific value (e.g., 9600 bps, 115200 bps) on both the transmitting and receiving UARTs. The configuration is typically done through software or hardware settings.</p>
</li>
<li>
<p><strong>Default Baud Rate:</strong> In some cases, UART devices may have default baud rate settings. If both devices are configured to use the same default baud rate, no additional configuration is necessary.</p>
</li>
<li>
<p><strong>Negotiation</strong>: In more advanced systems, UART devices may support auto-baud detection or negotiation protocols. Auto-baud detection allows a UART receiver to automatically determine the baud rate of incoming data by analyzing the timing of the start bits. This can be useful when the baud rate is not known in advance or may vary.</p>
</li>
<li>
<p><strong>Hardware Handshaking</strong>: In certain situations, UART communication may also involve hardware handshaking signals (such as RTS/CTS - Request to Send/Clear to Send) to coordinate communication between devices. These signals can help ensure that data is only transmitted when the receiving device is ready to receive it, reducing the risk of data loss or corruption.</p>
</li>
</ol>
<h3 id="the-uart-data-packet"><a class="header" href="#the-uart-data-packet">The UART data packet</a></h3>
<p>The format of the data packet needs to be agreed upon by the two communicating UART circuits as earlier mentioned.</p>
<p>The format is typically structured as follows....
<img src="uart_theory/img/data_packet_format.png" alt="Alt text" /></p>
<ul>
<li><strong>Start Bit</strong>: The start bit signals the beginning of the data byte. It is always set to a low voltage level (logic 0). The duration of the start bit is one bit duration, determined by the baud rate.</li>
</ul>
<p>The UART data transmission line is normally held at a high voltage level when it’s not transmitting data. To start the transfer of data, the transmitting UART pulls the transmission line from high to low for one clock cycle. When the receiving UART detects the high to low voltage transition, it begins reading the bits in the data frame at the frequency of the baud rate.</p>
<ul>
<li><strong>Data Bits</strong>: These are the actual bits representing the data being transmitted.<br />
The number of data bits can vary, but common configurations include 7 or 8 bits per data byte. It can be 5 bits up to 8 bits long if a parity bit is used. If no parity bit is used, the data frame can be 9 bits long.</li>
</ul>
<p>The data bits are typically transmitted LSB (Least Significant Bit) first. The duration of each data bit is determined by the baud rate.</p>
<ul>
<li><strong>Parity Bit (Optional)</strong>: The parity bit, if used, is an additional bit for error detection. It can be set to even parity, odd parity, mark parity, space parity, or no parity (none).</li>
</ul>
<p>Parity describes the evenness or oddness of a number. The parity bit is a way for the receiving UART to tell if any data has changed during transmission. Bits can be changed by electromagnetic radiation, mismatched baud rates, or long distance data transfers. After the receiving UART reads the data frame, it counts the number of bits with a value of 1 and checks if the total is an even or odd number. If the parity bit is a 0 (even parity), the 1 bits in the data frame should total to an even number. If the parity bit is a 1 (odd parity), the 1 bits in the data frame should total to an odd number. When the parity bit matches the data, the UART knows that the transmission was free of errors. But if the parity bit is a 0, and the total is odd; or the parity bit is a 1, and the total is even, the UART knows that bits in the data frame have changed.</p>
<ul>
<li><strong>Stop Bit(s)</strong>: The stop bit(s) signal the end of the data byte. Typically, one or two stop bits are used. The stop bit(s) are set to a high voltage level (logic 1). The duration of each stop bit is determined by the baud rate.</li>
</ul>
<h3 id="advantages-of-using-uarts"><a class="header" href="#advantages-of-using-uarts">Advantages of using UARTs</a></h3>
<ul>
<li>Simple, Only uses two wires</li>
<li>Simple, No clock signal is necessary.</li>
<li>Has a parity bit to allow for error checking</li>
<li>It can accomodate custom communication protocols; The structure of the data packet can be changed as long as both sides are set up for it</li>
<li>Well documented and widely used method</li>
</ul>
<h3 id="disadvantages-of-using-uarts"><a class="header" href="#disadvantages-of-using-uarts">Disadvantages of using UARTs</a></h3>
<ul>
<li>The size of the data frame is limited to a maximum of 9 bits.In scenarios where larger data sizes need to be transmitted, the limitation to 9 bits per frame can result in inefficiencies. It may require breaking down larger data sets into multiple frames, which can increase overhead and decrease overall efficiency.</li>
<li>Doesn’t support multiple slave or multiple master systems</li>
<li>The baud rates of each UART must be within 10% of each other</li>
</ul>
<h3 id="clarifications"><a class="header" href="#clarifications">Clarifications</a></h3>
<p>As seen from the image at the top of the page, the connection uses two wires to transmit data between devices. But in practice, you may use 3 wires for each device. For example, the 3 wires attached to UART 1 will be : </p>
<ul>
<li>The Transmitter wire (Tx wire) from UART 1 to UART 2</li>
<li>The Receiver wire (RX) from UART 2 to UART 1</li>
<li>The Ground wire</li>
</ul>
<h3 id="credits-and-references"><a class="header" href="#credits-and-references">credits and references</a></h3>
<ul>
<li>Credits go to this <a href="https://www.circuitbasics.com/basics-uart-communication/">circuitbasics blog</a>, for the images and elaborate content. You can give it a read.</li>
<li>If you want to learn about the different serial communication protocols associated with the UART, this <a href="https://www.raveon.com/wp-content/uploads/2019/01/AN236SerialComm.pdf">Raveon technical brief</a> provides a short overview</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="uart-registers"><a class="header" href="#uart-registers">UART Registers</a></h1>
<p>There are many UART designs and implementations each with different tweaks. So we will stick to the NS16550a UART because it was the one that the Qemu-riscv-virt machine emulates.</p>
<p>NS16550a UART is also kinda generic. It is an old design, but very simple. It gets the job done without clutter.<br />
The NS16550a also has two 16-byte FIFO buffers for input and output</p>
<p>If you want to check out the other different designs and implementations, go through this <a href="https://en.wikipedia.org/wiki/Universal_asynchronous_receiver-transmitter#UART_models">table</a>.</p>
<h2 id="references-and-docs"><a class="header" href="#references-and-docs">References and Docs</a></h2>
<p>Here are a few guiding docs that will help you learn more about the UART registers and configs.</p>
<ol>
<li><a href="https://www.lammertbies.nl/comm/info/serial-uart">A blog-like explanation by Lammert Bies</a> (start with this, it explains the most important bits without the electrical-engineering jargon)</li>
<li><a href="http://caro.su/msx/ocm_de1/16550.pdf">The 16550A datasheet</a> (use this as a reference. It comes with electrical-references that wil come in handy if you are writing a driver for a physical UART)</li>
</ol>
<p>The software that interacts with the UART 16550A can...</p>
<ol>
<li>Adjust the speed of both the receiver and transmitter</li>
<li>Configure character width</li>
<li>Configure data-frame format</li>
<li>Activate both the transmitter-buffer and receiver-buffer</li>
<li>Set the 16-byte buffers to either FIFO or non_FIFO</li>
</ol>
<p>There are two 16-byte buffers that come with the circuitry. These buffers are not part of the control registers. They are also NOT part of the data-buffer register(which is only one-byte long). They are independent physical buffers that can be activated or deactiated by the software during the initial configuration of the UART.</p>
<p>8 bytes of mmio needed to access the 12 registers of the UART this is because one register can be used to access mutiple registers o certain conditions.<br />
DLAB switch?<br />
Behaves differenctly when certain registors are set in a certain way</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="building-the-uart-on-qemu"><a class="header" href="#building-the-uart-on-qemu">Building the UART on qemu</a></h1>
<p>This chapter elaborates on how to write a UART driver for a virtual UART emulated by the <a href="https://www.qemu.org/">Qemu machine emulator</a>.<br />
The UART in this chapter is naive. It does not use standard &amp; safe abstractions. It is also blocking in nature.</p>
<p>The UART covered in the next-next chapter will be an improved of the UART covered in this chapter.</p>
<h2 id="qemu"><a class="header" href="#qemu">Qemu</a></h2>
<p>QEMU is a generic and open source machine emulator and virtualizer.</p>
<p>A machine emulator is a software program that simulates the behaviour of another computer or another computing system. For example you may simulate the behavior of a quantum computer on a convetional computer.</p>
<p>A virtualizer is a program that abstracts away an underlying system. The underlying system can be anything : Bare metal cpu, a hard disk, an operating system... anything.</p>
<p>QEMU can be used in several different ways. The most common is for System Emulation, where it provides a virtual model of an entire machine (CPU, memory and emulated devices) to run a guest OS. In this mode the CPU may be fully emulated, or it may work with a hypervisor such as KVM, Xen, Hax or Hypervisor.Framework to allow the guest to run directly on the host CPU.</p>
<p>The second supported way to use QEMU is User Mode Emulation, where QEMU can launch processes compiled for one CPU on another CPU. In this mode the CPU is always emulated.</p>
<p>In our project, we will use Qemu as a <a href="https://www.qemu.org/docs/master/system/target-riscv.html">Riscv System Emulator</a>.</p>
<h2 id="templates-hints"><a class="header" href="#templates-hints">Templates (hints)</a></h2>
<p>The next few chapters are going to be about setting things up. At the end of each sub-chapter, you will see a link to a finished template containing a cargo project that has been modified in accordance to the concerned sub-chapter.</p>
<p>The templates are not guaranteed to be always compile-worthy. They are meant to act as <strong>Hints</strong> -- Not copyable short-cuts. Try to understand them before moving on. Examine them, things will click with time.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="setting-things-up"><a class="header" href="#setting-things-up">Setting Things Up</a></h2>
<p>Under this chapter, we intend to answer the following 3 questions :</p>
<ol>
<li>What are we setting up?</li>
<li>Why are we setting up those things?</li>
<li>How are we seting up those things?</li>
</ol>
<h3 id="what-are-we-setting-up"><a class="header" href="#what-are-we-setting-up">What are we setting up?</a></h3>
<p>We are setting up the following components : </p>
<ol>
<li>A development toolchain</li>
<li>A RISCV virtual environment </li>
<li>A no-std Rust file.</li>
</ol>
<h4 id="the-development-toolchain"><a class="header" href="#the-development-toolchain">The development Toolchain</a></h4>
<p>A toolchain is a group of software tools that typically get used together...a chain of tools...<br />
In OS Development, the name toolchain usually refers to the combination of the compiler, linker, debugger and a bunch of programs that help in inspecting files. This toolchain gets used to convert source code into a format that can run on an execution <em>environment</em>.</p>
<p>An execution environment is a place where a software program can run. It provides the necessary resources, like the operating system and libraries, that the program needs to function. Examples of execution enviroments include: Bare metal, Browsers, Virtual Machines, Operating systems and Containers.</p>
<p>The toolchain in our case will consist of the following tools :</p>
<ol>
<li>The Rust Nightly Compiler with a riscv64gc-unknown-none-elf backend</li>
<li>linker : Rust-lld</li>
<li>Binutils </li>
</ol>
<p>To our luck, we do not have to install all these elements seperately. There exists compact toolchains :</p>
<ol>
<li>LLVM Riscv toolchain (ignore for now)</li>
<li>The GNU Riscv Toolchain (ignore for now)</li>
<li>The Rust Toolchain</li>
</ol>
<h4 id="why-we-need-the-toolchain"><a class="header" href="#why-we-need-the-toolchain">Why we need the toolchain</a></h4>
<p>We will have two kinds of source code files in our project : Rust source files and RISCV-Assembly files. Both of these types of files need to be turned into object files. Afterwards, those object files need to get linked together into a single executable file.<br />
To do all this, we need a compiler and a linker that can do cross-procesing.</p>
<p>We can go about this process of creating a single executable file in two ways:</p>
<h5 id="method-1"><a class="header" href="#method-1">Method 1</a></h5>
<p>We can compile the Rust files seperately from the Assembly files.<br />
Meaning that we will do the following actions in order : </p>
<ul>
<li>Use a stand-alone assembler to assemble the RISCV assembly files and turn them into object code.</li>
<li>Compile the RUST files into object code using a RUST_compiler.</li>
<li>Combine the all the resultant object files from the above 2 steps using a linker to form a single executable. </li>
</ul>
<h5 id="method-2"><a class="header" href="#method-2">Method 2</a></h5>
<p>We can embed the assembly code into the Rust source code.</p>
<p>That way, we only need one compilation, we will only need to compile the asm_embedded Rust files using the rust compiler. This method seems more of 'plug and play' because it does not need us to have a seperate riscv-asembler. It only requires us to have a rust-compiler only.</p>
<p>The disadvantage of this method is that we will always have to re-compile our entire project each time we change anything in any source file. But this is not really a problem; modern compilers are Fast, recompiling every file in our project is a matter of seconds.</p>
<p>Using method one will save up a few nano_seconds. A few nanoseconds is cheap price to pay.</p>
<p>Method 2  is a more user friendly method. Trading off negligible compile time over a user-friendliness in building and tweaking configurations is by far a very good choice.</p>
<p>Moreover, the rust compiler comes with its own inbuilt LLVM linker, rust-lld. That means that once we hit compile, we get the executable file output. One click, and all the build process runs inbuilt; from compiling rust files, to compiling assembly files, to creating a riscv-compliant executable file.</p>
<p>No more <a href="https://makefiletutorial.com/">Makefiles nightmares</a>, no more. This is very big news.<br />
For this reason, we will use Method 2.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="setting-up-the-compiler"><a class="header" href="#setting-up-the-compiler">Setting Up the Compiler</a></h1>
<p>The compiler is the tool that will convert our source code to machine code that suits a specific machine target.<br />
In our case, that specific machine target is <code>riscv64gc-unknown-none-elf</code>. ie &quot;The RISCV CPU, bare metal&quot;.</p>
<p>The rust compiler gets installed as a toolchain, so it comes with a linker attached. For this reason, our compile button will do the following : </p>
<ol>
<li>Compile rust files</li>
<li>Compile the embedded assembly files.</li>
<li>Link all the object files and produce an executable ELF file. (linker part)</li>
</ol>
<p>Ofcourse you can use a 3rd-party linker that you prefer, you are not forced to use the attached linker. But using another linker looks like a lot of unnecessary hard work tbh.</p>
<p>In the compiler world, people identify compilation targets using a standard naming convention called &quot;Target Triple&quot;.<br />
Initially the Target triple specified three characteristics of the machine target :</p>
<ul>
<li>CPU Architecture                         : eg x86, RISCV, ARM</li>
<li>Vendor who manufactures the target       : eg Apple, IBM</li>
<li>The operating system running on the CPU  : eg Linux, Windows, FreeBSD, None</li>
</ul>
<p>For example you would define a target as : ARM-Apple-IoS</p>
<p>But the world got more complex, now we have people naming things like... i don't know... it is not 3 characteristics anymore.   Sometimes you have 2 sometimes 5, 4 or 3.</p>
<p>So here is a 4 identifier description :</p>
<ul>
<li>CPU architecture</li>
<li>Vendor</li>
<li>Operating System</li>
<li>ABI</li>
</ul>
<p>Really, there is confusion, but hopefully you can tell what stands for what when you see a triple target with a weird number of identifiers.</p>
<h3 id="commands"><a class="header" href="#commands">Commands</a></h3>
<p>To install the Stable Rust compiler, enter the following comand :</p>
<pre><code class="language-bash">curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh  
</code></pre>
<p>Alternatively, you can visit this page : <a href="https://www.rust-lang.org/tools/install">Rust Compiler installation Main Page</a></p>
<p>Our project will use Nightly features. So you will need to install Rust Nightly :</p>
<pre><code class="language-bash">rustup toolchain install nightly  # install nightly Compiler
rustup default nightly            # set nightly Compiler as the default toolchain
</code></pre>
<p>The Machine Target we are compiling for is &quot;riscv64gc-unknown-none-elf&quot; which means we are compiling for </p>
<ul>
<li>&quot;<strong>riscv646gc</strong> -  64-bit-Riscv CPU that supports all general instructions ('g') and supports <a href="uart_implementations/on_qemu/./compressed_instructions.html">compressed instructions</a> ('c')</li>
<li><strong>unknown</strong> - means that the manufaturer of the CPU is unknown or that info is irrelevant</li>
<li><strong>none</strong> - means that the CPU has no operating system running on top of it</li>
<li><strong>elf</strong> - This component identifies the format of the output binary file that will be generated by the compiler. In this case, it specifies that the binary file will be in the ELF (Executable and Linkable Format) format, which is a common format used for executables and shared libraries on Unix-based systems.</li>
</ul>
<p>To check out all the targets that the compiler can support by default, type the following command :</p>
<pre><code class="language-bash">rustup target list               # list all supported targets
rustup target list --installed   # list all installed supported targets
</code></pre>
<p>To install our riscv64gc-unknown-none-elf target, enter the following command ;</p>
<pre><code class="language-bash">rustup target add riscv64gc-unknown-none-elf  # install a supported target
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="recap-on-writing-a-bare_metal_rust_executable"><a class="header" href="#recap-on-writing-a-bare_metal_rust_executable">Recap on writing a bare_metal_rust_executable</a></h1>
<h2 id="1-no_std"><a class="header" href="#1-no_std">1. NO_STD</a></h2>
<p>A bare metal executable is a rust program that can run on a piece of hardware without needing an operating system.</p>
<p>Since we are building a driver, we need to write it as a program that is not dependent on an operating system.<br />
Normal Rust programs depend on the rust standard library. The Rust standard library itself contains functions that call OS-specific system calls. So we cannot use the Rust std library.</p>
<p>We use the core Rust Library which is not environment-specific. The core library is dependency-free. It's only requirement is that the programmer provides the definitions of some linker symbols and language items. </p>
<p>To disable the std-dependence, we add the crate attribute <code>#![no_std]</code> to our project. </p>
<h2 id="2-no_main"><a class="header" href="#2-no_main">2. NO_MAIN</a></h2>
<p>Libc is a common C standard library that has been in use for a long time. It has been implemented for very many operating systems.<br />
Rust is a new language. It is very hard to implement the rust_std for all operating systems. To save on labour and allow compatibility, Rust creators decided to make the Rust Library to use libC functions instead of recreating the functions in pure Rust. Though there are some parts of the Rust std library that do not depend on libc.</p>
<p>Now that it is clear that rust_std depends on libc, when a rust bin is executed, the following events happen.</p>
<ol>
<li>The executable program is stored in the main memory (eg RAM)</li>
<li>The CPU points to the first instruction of the executable (the entry point). In this case, the entry point is the <code>_start</code> function found in the C runtime.</li>
<li>The C runtime sets up its environment in preparation for the libc functions that will get called by the rust_std functions</li>
<li>After the C runtime has set up the execution environment for the libc functions, it points to the entry point of the Rust Runtime.</li>
<li>The entry point of the Rust Runtime is marked with a language item called &quot;start&quot; ie [start]</li>
<li>So the Rust runtime creates an executable environment for executing the Rust functions.</li>
<li>After the Rust runtime has finished setting up things, it looks for the &quot;main&quot; function.</li>
<li>Main starts executing</li>
</ol>
<p>Our bare metal program does not depend on the C runtime. So this sequence of events is quite irrelevant to us.<br />
What we will do is that we will inform the compiler that we wont follow this sequence by : </p>
<ol>
<li>Adding the <code>#![no_main]</code> crate attribute to our project.</li>
<li>Declaring our own entry point function</li>
</ol>
<p>To declare our own entry point, we will export a function out of the crate... like so :</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[no_mangle] // The no_mangle attribute explained below
pub extern &quot;C&quot; fn _start()

// Mangling is a technique used by compilers to encode the names of 
// functions, methods, and other symbols in a program in a way that includes additional information beyond just the name itself. 

// For example `main` may become `main21212jxbjbjbkjckbdsc&amp;kbjbjksdbdjkbf`
// The primary purpose of mangling is to make sure that each variable or function is completely unique to
// the point that there are no name-conflicts during compilation and linking.  
// This also enables function overloading 

//In Rust, the #[no_mangle] attribute is used to instruct the compiler not to mangle the name of the item ...
// (function or static variable) during compilation. This is useful when you want to interface with external
//  code, like C code or assembly code, where the function names need to remain unchanged.  

// We want &quot;_start&quot; to be referenced as it is. We cannot gamble with the identity such a symbol name
<span class="boring">}</span></code></pre></pre>
<p>But that is not enough, we need to tell the linker the name of our entry_point function. We do this by writing a linker script that uses the <code>ENTRY</code> command.<br />
The linker will place the code as the first part of the .text section and update the elf header sections to reflect this info.</p>
<pre><code class="language-lds">...
OUTPUT_ARCH( &quot;riscv&quot; )


ENTRY( _start )  /* See? we have used the name `_start` just like it is. If name mangling had happened, we would have had some random name that changes with every compilation.  

MEMORY
{
  ram : ORIGIN = 0x80000000, LENGTH = 128M
}
</code></pre>
<h2 id="3-panic-handler"><a class="header" href="#3-panic-handler">3. Panic Handler</a></h2>
<p>Rust runtime panics when a violation happens. Rust requires you to define a function that will always get called after a panic happens.<br />
That function is tagged by the #[panic_handler] attribute.</p>
<p>The panic_handler function never returns anything, it diverges. It is therefore a divergent function.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use core::panic::PanicInfo;
#[panic_handler]
fn my_custom_function( panic_info: &amp;PanicInfo)-&gt; !{
    println!(&quot;message : {}&quot;, panic_info.message())
    println!(&quot;location : {}&quot;, panic_info.location())
}
<span class="boring">}</span></code></pre></pre>
<h2 id="4-the-eh_personality--aka-error_handling-personality"><a class="header" href="#4-the-eh_personality--aka-error_handling-personality">4. The eh_personality  (aka error_handling personality)</a></h2>
<p>Rust requires you to define a function that will always get called when it wants to unwind and free a stack.<br />
This function is tagged with #[eh_personality] attribute.</p>
<p>When a panic happens, the program stops (theoretically). The program can decide to free the stack or just abort and let the underlying OS clear the stack.<br />
The thing is, to clear the stack, you have to unwind it. To unwind the stack, you have to use some hard functions...Functions that depend on some OS functionalities. This is a chicken-egg problem.</p>
<p>So we resort to aborting.</p>
<p>To specify this behaviour, you can tweak the cargo file as follows : </p>
<pre><code class="language-toml">[profile.release]
panic = &quot;abort&quot;

[profile.dev]
panic = &quot;abort&quot;
</code></pre>
<p>By default the settings are usually :</p>
<pre><code class="language-toml">[profile.release]
panic = &quot;unwind&quot;

[profile.dev]
panic = &quot;unwind&quot;
</code></pre>
<p>Now, the #[eh_personality] tag is a tag that is pegged to the function that gets called when a rust program wants to unwind its stack. eg</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[eh_personality]
fn custom_unwind(){
    // do some unwinding statements ... MAgiC!
}
<span class="boring">}</span></code></pre></pre>
<p>BUT since we have specified that our program will always abort... AND that it will never call the unwind function, we are no longer required to define the unwinding function</p>
<h2 id="5-compile-for-a-bare_metal-target"><a class="header" href="#5-compile-for-a-bare_metal-target">5. Compile for a bare_metal target</a></h2>
<p>You can now compile for the speific target that you want. In our case, it is the <code>riscv64-unknown-none-elf</code>.<br />
To get a recap on how to perform cross-compiltion, re-visit <a href="uart_implementations/on_qemu/../../bare_metal/cross_compilation/cross_compilation.html">this chapter</a></p>
<h2 id="template-link"><a class="header" href="#template-link">Template Link</a></h2>
<p>You can view the template folder <a href="https://github.com/RustaceansKenya/driver-development-book/tree/master/chapter_snapshots/_0_bare">here</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="setting-up-the-riscv-virtual-environment"><a class="header" href="#setting-up-the-riscv-virtual-environment">Setting up the Riscv Virtual environment</a></h1>
<p>We will be using the <a href="https://www.qemu.org/docs/master/system/target-riscv.html">Qemu RISC-V System emulator</a> to emulate a RISCV-CPU microcontroller. </p>
<h3 id="installation"><a class="header" href="#installation">Installation</a></h3>
<p>To install Qemu, input the following terminal commands</p>
<pre><code class="language-bash">sudo apt install qemu-user
sudo apt install qemu-system-misc
</code></pre>
<h4 id="qemu-configurations"><a class="header" href="#qemu-configurations">Qemu Configurations</a></h4>
<p><em>1. Machine to be emulated</em><br />
For QEMU’s RISC-V system emulation, you must specify which board model you want to emulate with the <code>-M</code> or <code>--machine</code> Qemu-configuration option; there is no default machine selected.<br />
In our case, we will emulate the <a href="https://www.qemu.org/docs/master/system/riscv/virt.html">‘virt’ Generic Virtual Platform </a>as our target board model.</p>
<p><em>2. Booting mode</em><br />
When using the sifive_u or virt machine there are three different firmware boot options: </p>
<ol>
<li><code>-bios default</code> - This is the default behaviour if no -bios option is included. This option will load the default OpenSBI firmware automatically. The firmware is included with the QEMU release and no user interaction is required. All a user needs to do is specify the kernel they want to boot with the -kernel option </li>
<li><code>-bios none</code> - QEMU will not automatically load any firmware. It is up to the user to load all the images they need. </li>
<li><code>-bios &lt;file&gt;</code> - Tells QEMU to load the specified file as the firmware.</li>
</ol>
<p>We will use the following Qemu configurations ;</p>
<pre><code class="language-bash"># let's define some variables 
QEMU=qemu-system-riscv64  # we are using the Riscv Qemu emulator. qemu-system-riscv64 is a variable containing the path to the QEMU executable
MACH=virt                 # we will target the Virt Riscv Machine 
CPU=rv64                  # we will use a 64-bit CPU
CPUS=4                    # The Board will have 4 CPUs... 4 HARTS
MEM=128M                  # The RAM memory will be 128 MBs
<span class="boring"> # DRIVE=hdd.dsk             // This is the path to our virtual harddrive
</span>
# Let's substitute the above variables into Qemu-configuration options
$(QEMU) -machine $(MACH) 
        -cpu $(CPU)      
        -smp $(CPUS)     # specifies the number of CPUs to emulate
        -m $(MEM)        # specifies the amount of RAM in MBs 
        -nographic       # disables graphical output, so QEMU runs in a terminal window.
        -serial mon:stdio # connects the virtual machine motherboard's serial port to the host's system terminal. Ie, our Linux terminal. This enables us to use the terminal as a console to the virtual machine.
        -bios none       # we not depend on any firmware becaue our machine is virtual. We can just direclty load the kernel image to memory. 
        -kernel $(OUT)  # This specifies the path to the loader/driver/kernel image file
</code></pre>
<p>So whenever we run a Qemu emulation, we should run it with the above config files</p>
<h3 id="template"><a class="header" href="#template">Template</a></h3>
<p>There is no template for this subchapter. Try writing the qemu commands by hand before we integrate them to cargo.  </p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="setting-up-the-linker"><a class="header" href="#setting-up-the-linker">Setting up the linker</a></h1>
<p>References : </p>
<ul>
<li><a href="http://bravegnu.org/gnu-eprog/lds.html">Guide to Linker Scripting</a></li>
</ul>
<p>As earlier mentioned, the Rust compiler comes with an inbuilt linker. 
Each target comes with its own configured linker.</p>
<p>So by default we do not need a linker script. But for our case, we need a linker script.<br />
<br><br></p>
<p>So Why do we need a custom linker script?</p>
<h3 id="reason-1--to-define-the-entry-point"><a class="header" href="#reason-1--to-define-the-entry-point">Reason 1 : To define the Entry-Point</a></h3>
<p>Every program has an <a href="https://en.wikipedia.org/wiki/Entry_point">entry_point function</a>.<br />
An entry point is the place in a program where the execution of a program begins. Where the program-counter of the CPU will initially point to if it wants to run that program.</p>
<p>For example, Normal Rust programs that depend on the std library normally have their entry-point defined as '_start'. This &quot;_start&quot; function is typically defined as part of the C-runtime code.</p>
<p>In our case, the default linker used for the <code>riscv64-unknown-none-elf</code> automatically sets the entry point by trying each of the following methods in order, and stopping when one of them succeeds:</p>
<ul>
<li>The ` -e ' entry command-line option;</li>
<li>The ` ENTRY (symbol) ' command in a linker script;</li>
<li>The value of the symbol, start, if defined;</li>
<li>The address of the first byte of the ` .text ' section, if present;</li>
<li>The address, <code>0</code> in memory '.</li>
</ul>
<p>To avoid unpredictable behavior, we will explicitly declare the entry point in the linker script.</p>
<h3 id="reason-2-to-define-your-own-known-memory-addresses"><a class="header" href="#reason-2-to-define-your-own-known-memory-addresses">Reason 2: To define your own KNOWN memory addresses</a></h3>
<p>Here is the thing, an elf file has many sections and symbols; the global_data section, the heap, the stack, the bss, the text section...	</p>
<p>To write driver-level code, you need to explicitly <strong>KNOW</strong> the exact memory addresses of different elf sections and symbols. You need to <strong>KNOW</strong> the exact memory address for a particular function. You need to <strong>KNOW</strong> the exact memory address for the register that you want to read from. You need to <strong>KNOW</strong> the exact memory addresses for a lot of things.... </p>
<p>For example....<br />
when you want the driver-loader to load the driver, you may have to make the CPU instruction-pointer to point to the entry_point of the driver, you will need to give the driver-loader the exact memory address of the entry_point. Or maybe give it the address of the <code>text_section</code>.</p>
<p>Point is, to write driver code, you need to know the exact memory addresses of the different sections in your code in memory.</p>
<p>The linker script lets you <strong>define</strong> the exact memory addresses for the different elf sections and <code>points</code>. And the good thing is that the linker lets you label this <code>known memory points</code> using variables ie. <code>symbols</code>.	</p>
<p>Using the default linker script is wild; You let the linker decide the memory addresses for you.<br />
This means that you would have to constantly change your code to point to the addresses the linker chose for you. And the linker is not that deterministic. Today it places the heap here, tomorrow there.<br />
So it is best to define your own linker script that explicitly defines memory addresses that you KNOW.</p>
<p>&quot;Reject unpredictability, Embrace predictability&quot; - Zyzz</p>
<h3 id="reason-3-memory-alignment"><a class="header" href="#reason-3-memory-alignment">Reason 3: Memory Alignment</a></h3>
<p>You may want to make sure the different elf sections and symbols are aligned to a certain multiple. For example, if you plan to divide the Register mappings into 8-byte blocks, you may prefer to make the register_start memory address a multiple of 8</p>
<p>End of reasons...	</p>
<p>So how do we write a Linker Script? And which linker are we scripting for?</p>
<h3 id="which-linker-are-we-scripting-for"><a class="header" href="#which-linker-are-we-scripting-for">Which linker are we scripting for?</a></h3>
<p>The rust gives you an option to choose whichever linker you want to use.<br />
Rust uses the LLVM Linker by default. So we are currently scripting for the LLVM Linker.<br />
You may want to use other linkers based on your usecase. For example the LLVM linker is known for its advanced optimizations. The gold linker is optimized for elf files only, so it is lightweight and faster than the GNU linker. Meaning that you will not prefer the gold linker when creating non_elf files.</p>
<p>To know which linker version you are currently using, you can enter the command below :</p>
<pre><code class="language-bash">rustc --version --verbose
</code></pre>
<p>You get a result like this :</p>
<pre><code class="language-bash">rustc 1.70.0-nightly (f63ccaf25 2023-03-06)
binary: rustc
commit-hash: f63ccaf25f74151a5d8ce057904cd944074b01d2
commit-date: 2023-03-06Unleashed, this is the
starting memory address for our code
host: x86_64-unknown-linux-gnu
release: 1.70.0-nightly
LLVM version: 15.0.7
</code></pre>
<p>From the above result, you can see That <strong>LLVM linker is used</strong> and specifically version 15.0.7</p>
<p>But each target uses a particular linker flavour, what if you want more information about your current host target? What if you want information about another non_host target? Use the following command :</p>
<pre><code class="language-bash">rustc +nightly -Z unstable-options --target=wasm32-unknown-unknown --print target-spec-json   # for the nightly compiler

# OR
rustc  -Z unstable-options --target=riscv64gc-unknown-none-elf --print target-spec-json     #for the stable compiler

</code></pre>
<p>You can optionaly specify your linker of choice in the build manifest file (configuration file) - cargo.toml as follows :</p>
<pre><code class="language-toml">[target.'cfg(target_os = &quot;linux&quot;)'.llvm]
linker = &quot;/usr/bin/ld.gold&quot;                   //this specifies the path to the gold linker
</code></pre>
<p>But this is hard work, we are not taking that path. The less configurations we do, the more portable our code, the less headaches we get.<br />
So let's just use LLVM. For this project, ignore gold, GNU or any other linker.</p>
<h4 id="how-do-we-write-a-linker-script"><a class="header" href="#how-do-we-write-a-linker-script">How do we write a Linker Script?</a></h4>
<p>You can follow this tutorial <a href="http://bravegnu.org/gnu-eprog/lds.html">here</a></p>
<ul>
<li>Tell the linker which architecture you are targeting</li>
<li>You define the entry address of the elf file</li>
<li>Define all the memory that we have : RAM and ROM or just one of them </li>
</ul>
<p>The linker functions include :
- Resolving External symbols
- Section Merging
- Section Placement</p>
<p>We are writing the linker script so that we can instruct the linker on how it will do the section merging and section placement.</p>
<p><strong>Section merging</strong> is the process of combining similar elf sections from different files: For example if A.o and B.o were to be linked together to form C.o, then the linker will merge the <code>.text section</code> from both A and B and put the merged output into C ie. <code> A.text_section + B.text_section = C.text_sectiob</code>.</p>
<p><strong>Section placement</strong> is the process of specifying the virtual address of the different sections within the elf file. For example you may place the text section at 0x00 or 0x800... you name it. By default the linker places the different segments in adjacent to each other... but if you do this section placement process manually, you can set paddings between segments or jumble things up.</p>
<h3 id="exercise"><a class="header" href="#exercise">Exercise</a></h3>
<p>Write a linker script for the <a href="https://www.qemu.org/docs/master/system/riscv/virt.html"><code>‘virt’ Generic Virtual Platform</code></a>.<br />
The memory layout for the virtual board can be found <a href="https://github.com/qemu/qemu/blob/master/hw/riscv/virt.c#L63">here</a>.<br />
Come up with a linker script, even if it doesn't work. Try to figure it out.<br />
You can use the example below.<br />
<br><br></p>
<p>Below Linker script example that you can use for hints:</p>
<pre><code class="language-asm">/*
  define the architecture of the target that you are linking for.  
  for any RISC-V target (64-bit riscv is the name of the architectut or 32-bit).

  We will further refine this by using -mabi=lp64 and -march=rv64gc. But this will do for now.  s
*/
OUTPUT_ARCH( &quot;riscv&quot; )

/*
We're setting our entry point to a symbol
called _start which is inside of loader.s . This
essentially stores the address of _start as the
&quot;entry point&quot;, or where CPU instructions should start
executing.

In the rest of this script, we are going to place _start
right at the beginning of 0x8000_0000 because this is where
the virtual machine and many RISC-V boards will start executing.
*/
ENTRY( _start )

/*
The MEMORY section will explain that we have &quot;ram&quot; that contains
a section that is 'w' (writeable), 'x' (executable), and 'a' (allocatable).
We use '!' to invert 'r' (read-only) and 'i' (initialized). We don't want
our memory to be read-only, and we're stating that it is NOT initialized
at the beginning.

The ORIGIN is the memory address 0x8000_0000. If we look at the virt
spec or the specification for the RISC-V HiFive Unleashed, this is the
starting memory address for our code.

Side note: There might be other boot ROMs at different addresses, but
their job is to get to this point.

Finally LENGTH = 128M tells the linker that we have 128 megabyte of RAM.
The linker will double check this to make sure everything can fit.

The HiFive Unleashed has a lot more RAM than this, but for the virtual 
machine, I went with 128M since I think that's enough RAM for now.

We can provide other pieces of memory, such as QSPI, or ROM, but we're
telling the linker script here that we have one pool of RAM.
*/
MEMORY
{
  ram   (wxa!ri) : ORIGIN = 0x80000000, LENGTH = 128M
}

/*
PHDRS is short for &quot;program headers&quot;, which we specify three here:
text - CPU instructions (executable sections)
data - Global, initialized variables
bss  - Global, uninitialized variables (all will be set to 0 by boot.S)

The command PT_LOAD tells the linker that these sections will be loaded
from the file into memory.

We can actually stuff all of these into a single program header, but by
splitting it up into three, we can actually use the other PT_* commands
such as PT_DYNAMIC, PT_INTERP, PT_NULL to tell the linker where to find
additional information.

However, for our purposes, every section will be loaded from the program
headers.
*/
PHDRS
{
  text PT_LOAD;   
  data PT_LOAD;
  bss PT_LOAD;
}

/*
We are now going to organize the memory based on which
section it is in. In assembly, we can change the section
with the &quot;.section&quot; directive. However, in C++ and Rust,
CPU instructions go into text, global constants go into
rodata, global initialized variables go into data, and
global uninitialized variables go into bss.
*/
SECTIONS
{
  /*
    The first part of our RAM layout will be the text section.
	Since our CPU instructions are here, and our memory starts at
	0x8000_0000, we need our entry point to line up here.
  */
  .text : {
	  /* In the GNU Linker Script Language, the PROVIDE keyword instructs the linker to declare a new symbol and assign it a value 

	    PROVIDE allows me to create a symbol called _text_start so
		I know where the text section starts in the operating system.
		This should not move, but it is here for convenience.
		The period '.' tells the linker to set _text_start to the
		CURRENT location ('.' = current memory location). This current
		memory location moves as we add things.
	  */

    PROVIDE(_text_start = .);
	/*
	  We are going to layout all text sections here, starting with 
	  .text.init. 
	  The asterisk in front of the parentheses means to match
	  the .text.init section of ANY object file. Otherwise, we can specify
	  which object file should contain the .text.init section, for example,
	  boot.o(.text.init) would specifically put the .text.init section of
	  our bootloader here.

	  Because we might want to change the name of our files, we'll leave it
	  with a *.

	  Inside the parentheses is the name of the section. I created my own
	  called .text.init to make 100% sure that the _start is put right at the
	  beginning. The linker will lay this out in the order it receives it:

	  .text.init first
	  all .text sections next
	  any .text.* sections last

	  .text.* means to match anything after .text. If we didn't already specify
	  .text.init, this would've matched here. The assembler and linker can place
	  things in &quot;special&quot; text sections, so we match any we might come across here.
	*/
    *(.text.init) *(.text .text.*)

	/*
	  Again, with PROVIDE, we're providing a readable symbol called _text_end, which is
	  set to the memory address AFTER .text.init, .text, and .text.*'s have been added.
	*/
    PROVIDE(_text_end = .);
	/*
	  The portion after the right brace is in an odd format. However, this is telling the
	  linker what memory portion to put it in. We labeled our RAM, ram, with the constraints
	  that it is writeable, allocatable, and executable. The linker will make sure with this
	  that we can do all of those things.

	  &gt;ram - This just tells the linker script to put this entire section (.text) into the
	         ram region of memory. To my knowledge, the '&gt;' does not mean &quot;greater than&quot;. Instead,
			 it is a symbol to let the linker know we want to put this in ram.

	  AT&gt;ram - This sets the LMA (load memory address) region to the same thing.this linker script, we're loading
			   everything into its physical location. We'll l LMA is the final
	           translation of a VMA (virtual memory address). With et the kernel copy and sort out the 
			   virtual memory. That's why &gt;ram and AT&gt;ram are continually the same thing.

	  :text  - This tells the linker script to put this into the :text program header. We've only
	           defined three: text, data, and bss. In this case, we're telling the linker script
			   to go into the text section.
	*/
  } &gt;ram AT&gt;ram :text
   /*
     The global pointer allows the linker to position global variables and constants into
	 independent positions relative to the gp (global pointer) register. The globals start
	 after the text sections and are only relevant to the rodata, data, and bss sections.
   */
   PROVIDE(_global_pointer = .);
   /*
     Most compilers create a rodata (read only data) section for global constants. However,
	 we're going to place ours in the text section. We can actually put this in :data, but
	 since the .text section is read-only, we can place it there.

	 NOTE: This doesn't actually do anything, yet. The actual &quot;protection&quot; cannot be done
	 at link time. Instead, when we program the memory management unit (MMU), we will be
	 able to choose which bits (R=read, W=write, X=execute) we want each memory segment
	 to be able to do.
   */
  .rodata : {
    PROVIDE(_rodata_start = .);
    *(.rodata .rodata.*)
    PROVIDE(_rodata_end = .);
	/*
	   Again, we're placing the rodata section in the memory segment &quot;ram&quot; and we're putting
	   it in the :text program header. We don't have one for rodata anyway.
	*/
  } &gt;ram AT&gt;ram :text

  .data : {
	/*
	   . = ALIGN(4096) tells the linker to align the current memory location (which is
	   0x8000_0000 + text section + rodata section) to 4096 bytes. This is because our paging
	   system's resolution is 4,096 bytes or 4 KiB.

	   As a result, the current memory address is rounded off to the next nearest address that has a value that is a multiple of 4096
	*/
    . = ALIGN(4096);
    PROVIDE(_data_start = .);
	/*
	   sdata and data are essentially the same thing. However, compilers usually use the
	   sdata sections for shorter, quicker loading sections. So, usually critical data
	   is loaded there. However, we're loading all of this in one fell swoop.
	   So, we're looking to put all of the following sections under the umbrella .data:
	   .sdata
	   .sdata.[anything]
	   .data
	   .data.[anything]

	   ...in that order.
	*/
    *(.sdata .sdata.*) *(.data .data.*)
    PROVIDE(_data_end = .);
  } &gt;ram AT&gt;ram :data

  .bss : {
    PROVIDE(_bss_start = .);
    *(.sbss .sbss.*) *(.bss .bss.*)
    PROVIDE(_bss_end = .);
  } &gt;ram AT&gt;ram :bss

  /*
     The following will be helpful when we allocate the kernel stack (_stack) and
	 determine where the heap begins and ends (_heap_start and _heap_start + _heap_size)/
	 When we do memory allocation, we can use these symbols.

	 We use the symbols instead of hard-coding an address because this is a floating target.
	 Floating target means that the address space layout keeps on changing, do it becomes hard to hardcode physical adresses.
	 The heap size is not known at compile time
	 As we add code, the heap moves farther down the memory and gets shorter.

	 _memory_start will be set to 0x8000_0000 here. We use ORIGIN(ram) so that it will take
	 whatever we set the origin of ram to. Otherwise, we'd have to change it more than once
	 if we ever stray away from 0x8000_0000 as our entry point.
  */
  PROVIDE(_memory_start = ORIGIN(ram));
  /*
     Our kernel stack starts at the end of the bss segment (_bss_end). However, we're allocating
	 0x80000 bytes (524 KiB) to our kernel stack. This should be PLENTY of space. The reason
	 we add the memory is because the stack grows from higher memory to lower memory (bottom to top).
	 Therefore we set the stack at the very bottom of its allocated slot.
	 When we go to allocate from the stack, we'll subtract the number of bytes we need.
  */
  PROVIDE(_stack = _bss_end + 0x80000);
  PROVIDE(_memory_end = ORIGIN(ram) + LENGTH(ram));

  /* 
     Finally, our heap starts right after the kernel stack. This heap will be used mainly
	 to dole out memory for user-space applications. However, in some circumstances, it will
	 be used for kernel memory as well.

	 We don't align here because we let the kernel determine how it wants to do this.
  */
  PROVIDE(_heap_start = _stack);
  PROVIDE(_heap_size = _memory_end - _stack);
}

</code></pre>
<h3 id="template-1"><a class="header" href="#template-1">Template</a></h3>
<p>You can view the template folder <a href="https://github.com/RustaceansKenya/driver-development-book/tree/master/chapter_snapshots/_1_bare_with_script">here</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="setting-up-the-build-automation-tool"><a class="header" href="#setting-up-the-build-automation-tool">Setting up the Build automation tool</a></h1>
<p>Our build tool will be cargo.<br />
We will not use third party build tools like Makefiles.<br />
It is better to not use 3rd parties.</p>
<p>So create a .cargo folder withing the repo.<br />
Create a config.toml inside the folder</p>
<p>So you have : project/.cargo/config.toml.
Inside this file, paste the following configurations : </p>
<pre><code class="language-toml">[build]
target = &quot;riscv64gc-unknown-none-elf&quot;
rustflags = ['-Clink-arg=-Tsrc/lds/virt.lds']

[target.riscv64gc-unknown-none-elf]
runner = &quot;qemu-system-riscv64 -machine virt -cpu rv64 -smp 4 -m 128M -serial mon:stdio -nographic -bios none -kernel &quot;	
</code></pre>
<p>The [build] section has configs that affect the compilation process. We tell the compiler our target platform. And tell the linker the path to the linker script.</p>
<p>The [target.riscv64gc-unknown-none-elf] section has the configs that will be considered only if we are compiling for the riscv64gc-unknown-none-elf target.<br />
The &quot;runner&quot; specifies the cmd command that will be executed when we call &quot;Cargo run&quot;. There is a space after -kernel. This is because cargo will automatically specify the executable, whose name is configured through Cargo.toml. </p>
<h3 id="template-2"><a class="header" href="#template-2">Template</a></h3>
<p>You can view the template folder <a href="https://github.com/RustaceansKenya/driver-development-book/tree/master/chapter_snapshots/_2_bare_with_runner">here</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="loaders-and-bootloaders"><a class="header" href="#loaders-and-bootloaders">Loaders and Bootloaders</a></h1>
<p>Now that we have written a compile-worthy no-std binary... what next?</p>
<p>We cannot just run a driver on metal like that. We need to have a program that boots up the machine before running our driver(our no-std file).</p>
<p>And for this purpose, we introduce two new parties : <strong>Loaders</strong> and <strong>Bootloaders</strong>.<br />
Our firmware needs to get loaded into memory by either the Loader or the Bootloader.</p>
<h2 id="difference-between-a-loader-and-a-bootloader"><a class="header" href="#difference-between-a-loader-and-a-bootloader">Difference between a loader and a bootloader.</a></h2>
<p>A loader and a bootloader are both involved in the process of loading software into memory(*<em>RAM</em>) for execution, but they serve different purposes and operate at different stages of the system startup process.</p>
<h3 id="bootloader"><a class="header" href="#bootloader">Bootloader:</a></h3>
<p>A bootloader is a small program that is executed when a computer system is powered on or restarted. Its primary function is to initialize the hardware, perform basic system checks, and load the operating system into memory for execution.</p>
<p>Bootloaders are typically stored in a specific location on the storage device (e.g., the Master Boot Record on a hard disk drive or in the boot ROM of an embedded system).</p>
<p>The bootloader is responsible for locating the operating system kernel, loading it into memory, and transferring control to the kernel to begin the boot process.<br />
Examples of bootloaders include GRUB (Grand Unified Bootloader) and U-Boot (Universal Bootloader), which are commonly used in Linux systems.</p>
<p>But in our case, since we do not have a kernel in sight, the bootloader will load <em><strong>our no-std file</strong></em>. Our no-std file will act as a temporary kernel... or rather, it will act as an execution runtime that can call the UART driver whenever it is needed.</p>
<h3 id="loader"><a class="header" href="#loader">Loader:</a></h3>
<p>A loader, also known as a program loader, is a component of an operating system that loads executable files from storage(eg SSD) into memory(eg RAM) and prepares them for execution.</p>
<p>Loaders operate after the operating system kernel has been loaded and initialized by the bootloader. They are responsible for loading user-space programs, shared libraries, and other executable files as needed during the runtime of the system.</p>
<p>Loaders perform tasks such as resolving external references, allocating memory for program code and data, setting up the program's execution environment, and transferring control to the entry point of the program.<br />
In some cases, the term &quot;loader&quot; may also refer to a component of a development toolchain responsible for generating executable files from source code by linking together various object files and libraries.</p>
<p>So in our case, the loader will a part of the execution runtime (ie our no-std file that was acting as a minimal kernel)</p>
<p>The loader will have the following functions :</p>
<ul>
<li>listen for loading &amp; unloading orders from the minimal-kernel</li>
<li>execute the the loading and unloading.</li>
</ul>
<p>Loading a program involves things such as ; </p>
<ul>
<li>copying the Program's loadable-elf-sections from ROM/HDD/SDD and putting them in the RAM.</li>
<li>adjusting the necessary CPU registers. For example, making the Program counter to point to the entry point of the program that needs to be loaded.</li>
<li>Setup stack-protection (if necessary)</li>
<li>Ensuring that the metadata for the program is available for the minimal-kernel.</li>
</ul>
<p>Unloading a program involves things such as :</p>
<ul>
<li>cleaning the program stack and zeroing out any 'confidential' program sections to avoid data-stealing.</li>
<li>adjusting the necessary CPU registers. For example, making the Program counter to point back to the minimal kernel</li>
</ul>
<h2 id="bootloaders-in-qemu-riscv-virt-machine"><a class="header" href="#bootloaders-in-qemu-riscv-virt-machine">Bootloaders in Qemu-Riscv Virt machine</a></h2>
<p>When using the sifive_u or virt machine in Qemu, there are three different firmware boot options:</p>
<pre><code class="language-bash">-bios default # option 1
</code></pre>
<p>This is the default behaviour if no -bios option is included. This option will load the default OpenSBI firmware automatically. The firmware is included with the QEMU release and no user interaction is required. All a user needs to do is specify the kernel they want to boot with the -kernel option.<br />
<br></p>
<pre><code class="language-bash">-bios none    # option 2
</code></pre>
<p>QEMU will not automatically load any firmware. It is up to the user to load all the images they need.<br />
<br></p>
<pre><code class="language-bash">-bios &lt;file&gt;  # option 3
</code></pre>
<p>Tells QEMU to load the specified file as the firmware.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-bootloader"><a class="header" href="#the-bootloader">The Bootloader</a></h1>
<p>Since we are not booting the typical kernel, let us stop using the term bootloader. let's use the word <code>start-up code</code>.</p>
<p>Calling it bootloader implies that it does esoteric functions such as performing a <code>power-on self test</code> and loading secondary loaders. So we will stick to the name <code>startup code</code>.</p>
<p>The startup code does the following actions : </p>
<ol>
<li>It describes a function that helps us find the correct exception handlers. Something like an <code>switch</code> for exception-handling functions</li>
<li>Chooses a HART/CORE that will execute the rest of the activities below</li>
<li>Copies all initialized data from FLASH to RAM.</li>
<li>Copies all un-initialized data from FLASH to RAM.</li>
<li>Zeroes-out all the un-initialized data</li>
<li>Sets up the stack pointer</li>
<li>Calls the <code>main</code> function in our rust code</li>
</ol>
<p>Our start-up code will be written in Riscv Assembly.<br />
We will embed those assembly files as part of our rust files.</p>
<p>You can find books to help you learn riscv in the <a href="https://github.com/RustaceansKenya/driver-development-book/tree/master/reading_resources">reading_resources folder</a></p>
<h3 id="template-3"><a class="header" href="#template-3">Template</a></h3>
<p>You can view the template folder <a href="https://github.com/RustaceansKenya/driver-development-book/tree/master/chapter_snapshots/_3_with_startup_code">here</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="notable-crates"><a class="header" href="#notable-crates">Notable Crates</a></h1>
<h2 id="for-bare-metal-programming"><a class="header" href="#for-bare-metal-programming">For bare metal programming</a></h2>
<ul>
<li>heapless</li>
<li>critical-section</li>
<li>portable-atomic</li>
<li>bit-field, bitfield</li>
<li>bit-flags</li>
<li>embedded-hal</li>
<li>embedded-dma : This library provides the ReadBuffer and WriteBuffer unsafe traits to be used as bounds to buffers types used in DMA operations.</li>
<li>fugi : time crate for embedded systems</li>
<li>nb : Minimal and reusable non-blocking I/O layer</li>
<li>riscv</li>
<li>riscv-rt</li>
<li>volatile-register</li>
<li>vcell : Just like Cell but with volatile read / write operations</li>
</ul>
<h2 id="utility-like"><a class="header" href="#utility-like">Utility-like</a></h2>
<ul>
<li>svd2rust + form + rustfmt</li>
<li>defmt : A highly efficient logging framework that targets resource-constrained devices, like microcontrollers.
Check out the defmt book at https://defmt.ferrous-systems.com for more information about how to use it.</li>
<li>embassy crates</li>
<li>probe crates</li>
<li>clap</li>
<li>ratatui</li>
<li>serde</li>
</ul>
<h2 id="panicking"><a class="header" href="#panicking">Panicking</a></h2>
<ul>
<li>panic-abort. A panic causes the abort instruction to be executed.</li>
<li>panic-halt. A panic causes the program, or the current thread, to halt by entering an infinite loop.</li>
<li>panic-itm. The panicking message is logged using the ITM, an ARM Cortex-M specific peripheral.</li>
<li>panic-semihosting. The panicking message is logged to the host using the semihosting technique.</li>
<li>more here : https://crates.io/keywords/panic-handler</li>
</ul>
<h3 id="more-tertiary-for-now"><a class="header" href="#more-tertiary-for-now">more tertiary for now</a></h3>
<ul>
<li>cfg-if  : A macro for defining #[cfg] if-else statements.</li>
<li></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><ol>
<li>core::mem</li>
<li>core::ptr</li>
<li>core::alloc  // Thiis is different from the Alloc crate</li>
<li>core::fmt</li>
<li>core::panic</li>
<li>core::cell</li>
<li>core::ffi</li>
<li>core::io</li>
<li>core::error</li>
<li>The rest of the modules are somehow secondary</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="why-embedded-rust"><a class="header" href="#why-embedded-rust">Why Embedded Rust</a></h1>
<h2 id="memory-safety"><a class="header" href="#memory-safety">Memory Safety:</a></h2>
<p>Rust's ownership system and borrow checker ensure memory safety without the need for a garbage collector. This helps prevent common issues like null pointer dereferences, buffer overflows, and data races.</p>
<h2 id="concurrency-and-parallelism"><a class="header" href="#concurrency-and-parallelism">Concurrency and Parallelism:</a></h2>
<p>Advantage: Rust provides ownership-based concurrency control, allowing developers to write concurrent code without the risk of data races. The language's emphasis on zero-cost abstractions enables efficient parallelism.</p>
<h2 id="nice-integration-with-c-and-c-and-their-respective-tools"><a class="header" href="#nice-integration-with-c-and-c-and-their-respective-tools">Nice integration with C and C++... and their respective tools</a></h2>
<ul>
<li>Rust has a robust FFI that allows seamless integration with C and C++ code.</li>
<li>Cargo integrates well with tools that are popular in the embedded world, so a C developer needs not learn ALL NEW things. For example the default toolchain components are extended LLVM or GNU components. You can integrate C library and build tools in a seamless manner in your project.</li>
</ul>
<h2 id="ergonomics"><a class="header" href="#ergonomics">Ergonomics</a></h2>
<ul>
<li>Tools are considerably documented.</li>
<li>Helpful community</li>
<li>many helpful tools &amp; crates... especially the compiler itself. </li>
</ul>
<p>Naive but somehow true perspective : Rust enables you to write complex software (even as a junior), your implementation is not 100% dependent on your experience level.</p>
<div style="break-before: page; page-break-before: always;"></div><h3 id="newlib"><a class="header" href="#newlib">Newlib</a></h3>
<p>Newlib is a lightweight and efficient C library primarily designed for embedded systems and other resource-constrained environments. It provides standard C library functionality, including input/output, string manipulation, memory management, and more, while prioritizing small size and minimal overhead. Although it aims to offer POSIX compatibility, Newlib may not implement the full range of POSIX functions found in larger libraries like glibc. Suitable for standalone usage or integration into embedded development toolchains, Newlib serves as a practical choice for projects where conserving resources is paramount and where comprehensive POSIX compliance is not a strict requirement.</p>
<p><a href="https://sourceware.org/newlib/">newlib official homepage</a></p>
<h3 id="glibc-gnu-c-library"><a class="header" href="#glibc-gnu-c-library">glibc (GNU C Library):</a></h3>
<p>glibc is the standard C library for the GNU operating system and most Linux distributions.<br />
It provides comprehensive POSIX compatibility and a wide range of features, but it is relatively large and may not be suitable for embedded systems with limited resources.</p>
<h3 id="musl-libc"><a class="header" href="#musl-libc">musl libc:</a></h3>
<p>musl is a lightweight, fast, and efficient C library that aims to provide POSIX compatibility with minimal overhead. It is designed to be small and suitable for embedded systems and other resource-constrained environments.</p>
<p>If you intend to primarily write your code in Rust and want to leverage the Rust ecosystem, using the Generic ELF/Newlib toolchain might not be the most desirable option. Here's why:</p>
<pre><code>Compatibility: The Generic ELF/Newlib toolchain is primarily tailored for C development, particularly in embedded systems or bare-metal environments. While Rust can interoperate with C code, using Newlib might introduce additional complexity when working with Rust code.

Standard Library: Rust provides its standard library (std), which is designed to work across different platforms and environments. By default, Rust code targets libstd, which provides a rich set of functionality beyond what Newlib offers. Using the Generic ELF/Newlib toolchain might limit your ability to leverage Rust's standard library and ecosystem.

Community Support: Rust has a vibrant community and ecosystem, with many libraries and tools developed specifically for Rust. Using the Generic ELF/Newlib toolchain might limit your access to these resources, as they are often designed to work with Rust's standard library (std) rather than Newlib.

Maintenance: While it's possible to use Rust with the Generic ELF/Newlib toolchain, maintaining Rust code alongside C code compiled with Newlib might introduce challenges, especially if you're not already familiar with both languages and their respective toolchains.
</code></pre>
<p>Instead, if you intend to write mostly in Rust, consider using toolchains and libraries that are specifically designed for Rust development in embedded systems or bare-metal environments. For example, you could use toolchains targeting libcore or libraries like cortex-m, embedded-hal, or vendor-specific hal crates, which provide idiomatic Rust interfaces for interacting with hardware and low-level system functionality. These options are more aligned with Rust's design principles and ecosystem and might provide a smoother development experience for Rust-centric projects.</p>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><h1 id="apis"><a class="header" href="#apis">APIs</a></h1>
<h2 id="what-is-an-api"><a class="header" href="#what-is-an-api">What is an API?</a></h2>
<p>Application Programming Interface is a set of rules (diguised as functions), protocols, and tools that allows different software applications to communicate and interact with each other.</p>
<p>It does so by defining the methods and data formats that developers can use to request and exchange information between software components.</p>
<p>So you can say an API is the interface for an application. It contains objects and functions that can be called by other apps.</p>
<p>Here are some examples of different APIs .... </p>
<h3 id="example-1-library-api"><a class="header" href="#example-1-library-api">Example 1 (Library API):</a></h3>
<p>The simplest and common type of API is a <strong>Library API</strong>. Library APIs define the methods, classes, and data structures that developers can use when programming with the library.</p>
<p>For example, If you are trying to write an CLI-app that prints a random number on screen, chances are that you might import and use the <code>rand</code> library/crate. Here is the 'rand' crate's <a href="https://docs.rs/rand/0.8.5/rand/">library API documentation</a>: </p>
<p>The [<code>rand</code>] library exposes <a href="https://docs.rs/rand/0.8.5/rand/#functions">these functions</a>, <a href="https://docs.rs/rand/0.8.5/rand/#traits">these traits</a> and <a href="https://docs.rs/rand/0.8.5/rand/#structs">this struct</a> as its API. If you use the rand crate in your app, you can interact with it by bringing these exposed items in the scope of your app.</p>
<h3 id="example-2-kernel-api"><a class="header" href="#example-2-kernel-api">Example 2 (Kernel API):</a></h3>
<p><strong>Operating System APIs</strong> are provided by operating systems to allow applications to interact with system resources such as files, processes, and devices. They provide a way for applications to access low-level functionality without needing to understand the underlying hardware or system architecture.</p>
<p>Here is the <a href="https://archive.kernel.org/oldlinux/htmldocs/kernel-api/">Linux Kernel API</a>.<br />
From the page, you can see it exposing datatypes and functions. For example, It exposes the <a href="https://archive.kernel.org/oldlinux/htmldocs/kernel-api/adt.html#id-1.3.2"><code>Doubly Linked List</code></a> and all the <code>methods</code> associated with that doubly-linked-list.</p>
<h4 id="example-3-database-apis"><a class="header" href="#example-3-database-apis">Example 3 (Database APIs):</a></h4>
<p><strong>Database APIs</strong> provide a way for applications to interact with databases, allowing them to perform operations such as querying data, inserting records, and updating information.<br />
For example a relational database may expose functions that assist the programmer in creating, modifying and deleting tables.</p>
<p>APIs enable interoperability between different software systems, allowing them to work together seamlessly. They abstract away the complexities of underlying systems and provide a standardized interface that developers can use to build applications.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="abis"><a class="header" href="#abis">ABIs</a></h1>
<h2 id="what-is-an-abi"><a class="header" href="#what-is-an-abi">What is an ABI?</a></h2>
<p>An ABI (Application Binary Interface) is a set of specifications defining.... </p>
<h3 id="post-runtime-specs"><a class="header" href="#post-runtime-specs">Post runtime specs</a></h3>
<ol>
<li><strong>Data representation</strong>: How data types are represented in memory, including issues like endianness (byte order), alignment, and padding.</li>
<li><strong>Object file formats</strong>: The structure and layout of object files, which contain compiled code and data before they are linked into an executable. </li>
</ol>
<h3 id="runtime-specs"><a class="header" href="#runtime-specs">Runtime specs</a></h3>
<ol start="3">
<li><strong>Dynamic linking</strong>: How dynamically linked libraries are loaded and resolved at runtime.</li>
<li><strong>Function calling conventions</strong>: How parameters are passed to functions, how return values are returned, and how functions are invoked.</li>
</ol>
<ul>
<li>https://stackoverflow.com/questions/2171177/what-is-an-application-binary-interface-abi</li>
</ul>
<p>THe ABI defines the :</p>
<ol>
<li>Calling conventions</li>
<li>How parameter are passed</li>
<li>Object file format</li>
<li>Executable file format</li>
<li>stack frame layout</li>
<li>How types get encoded 
<ul>
<li>endianness</li>
<li>lengths</li>
<li>encode pattern (eg characters use UTF-8)</li>
<li></li>
</ul>
</li>
<li>ddsd</li>
</ol>
<h3 id="the-c-abi"><a class="header" href="#the-c-abi">The C ABI?</a></h3>
<p>C itself as a language standard doesn't define a specific ABI (Application Binary Interface). Instead, the ABI is typically determined by the platform and compiler being used. An ABI defines how functions are called, how parameters are passed, how data is laid out in memory, and other low-level details necessary for binary compatibility between separately compiled modules.</p>
<p>Different compilers and platforms may have their own ABIs. For example:</p>
<pre><code>x86-64 System V ABI: This is the ABI commonly used on many Unix-like operating systems for 64-bit x86 processors. It specifies how parameters are passed, how the stack is managed, how functions are called, etc.

Windows x64 ABI: Microsoft Windows uses its own ABI for 64-bit x86 processors, which differs in certain aspects from the System V ABI.

ARM EABI: The Embedded Application Binary Interface for ARM processors, which defines how code should be compiled and linked for ARM-based systems.

RISC-V ABIs: As discussed earlier, there are several ABIs for RISC-V processors, such as ilp32, lp64, etc.
</code></pre>
<h3 id="riscv-abis"><a class="header" href="#riscv-abis">Riscv ABIs</a></h3>
<h4 id="messes"><a class="header" href="#messes">Messes</a></h4>
<ul>
<li>see symbol table and learn to understand it</li>
<li>see relocation table and learn to understand it</li>
<li>disassemble a program</li>
<li>assemble a program</li>
<li>link a couple of object files into an executable, observe the relocation</li>
<li>see the undefined reference in object symbol and relocation table. Before and after linking</li>
</ul>
<h3 id="on-using-gnu-based-toolchains"><a class="header" href="#on-using-gnu-based-toolchains">On using GNU-based toolchains</a></h3>
<p>If you intend to primarily write your code in Rust and want to leverage the Rust ecosystem, using the Generic ELF/Newlib toolchain might not be the most desirable option. Here's why:</p>
<pre><code>Compatibility: The Generic ELF/Newlib toolchain is primarily tailored for C development, particularly in embedded systems or bare-metal environments. While Rust can interoperate with C code, using Newlib might introduce additional complexity when working with Rust code.

Standard Library: Rust provides its standard library (std), which is designed to work across different platforms and environments. By default, Rust code targets libstd, which provides a rich set of functionality beyond what Newlib offers. Using the Generic ELF/Newlib toolchain might limit your ability to leverage Rust's standard library and ecosystem.

Community Support: Rust has a vibrant community and ecosystem, with many libraries and tools developed specifically for Rust. Using the Generic ELF/Newlib toolchain might limit your access to these resources, as they are often designed to work with Rust's standard library (std) rather than Newlib.

Maintenance: While it's possible to use Rust with the Generic ELF/Newlib toolchain, maintaining Rust code alongside C code compiled with Newlib might introduce challenges, especially if you're not already familiar with both languages and their respective toolchains.
</code></pre>
<p>Instead, if you intend to write mostly in Rust, consider using toolchains and libraries that are specifically designed for Rust development in embedded systems or bare-metal environments. For example, you could use toolchains targeting libcore or libraries like cortex-m, embedded-hal, or vendor-specific hal crates, which provide idiomatic Rust interfaces for interacting with hardware and low-level system functionality. These options are more aligned with Rust's design principles and ecosystem and might provide a smoother development experience for Rust-centric projects.</p>
<div style="break-before: page; page-break-before: always;"></div><p>An ISA specification is a piece of document that elaborates on how a certain processor functions. It does so by explaining the things listed below :</p>
<ul>
<li>
<p>Supported Instructions:
This refers to the set of operations or commands that a processor can understand and execute. Instructions could include arithmetic operations (addition, subtraction, multiplication, division), logical operations (AND, OR, NOT), control flow operations (branches, jumps, calls), and others specific to the architecture.</p>
</li>
<li>
<p>Data Types:
ISA specifies the types of data that can be manipulated by the processor. This might include integer types (such as 8-bit, 16-bit, 32-bit, or 64-bit integers), floating-point types (single precision, double precision), and sometimes vector or SIMD (Single Instruction, Multiple Data) types for parallel processing.</p>
</li>
<li>
<p>Registers:
Registers are small, fast storage locations within the processor that hold data temporarily during processing. ISA defines the number of registers, their sizes, and their intended purposes (e.g., general-purpose registers, special-purpose registers for specific tasks like storing the program counter or stack pointer).</p>
</li>
<li>
<p>Hardware Support for Managing Main Memory:
ISA specifies how the processor interacts with main memory (RAM). This includes mechanisms for loading and storing data from/to memory, handling memory access permissions, cache management, and mechanisms for memory protection to prevent unauthorized access.</p>
</li>
<li>
<p>Fundamental Features:
These are core aspects of the ISA that define its behavior and capabilities.
Memory Consistency: Specifies how memory accesses by different parts of a program are ordered and synchronized.
Addressing Modes: Defines the various ways in which memory addresses can be specified in instructions (e.g., direct addressing, indirect addressing, indexed addressing).
Virtual Memory: Defines how the processor interacts with virtual memory systems, including mechanisms for address translation between virtual and physical memory, page tables, and memory protection.</p>
</li>
<li>
<p>Input/Output Model:
This refers to how the processor communicates with peripheral devices such as keyboards, displays, storage devices, and network interfaces. ISA specifies the instructions and mechanisms for transferring data between the processor and these devices, often through dedicated I/O instructions or memory-mapped I/O.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><p>Reference crates : </p>
<ul>
<li>
<p>cortex-m-rt</p>
</li>
<li>
<p>riscv-rt</p>
</li>
<li>
<p>combiation of startupcode + runtime code</p>
</li>
</ul>
<h3 id="functions-of-startup-code"><a class="header" href="#functions-of-startup-code">Functions of startup code</a></h3>
<ul>
<li>
<p>Sets up the memory layout of the program. In particular, it populates the vector table so the device can boot correctly, and properly dispatch exceptions and interrupts.</p>
</li>
<li>
<p>Initializing static variables before the program entry point.</p>
</li>
<li>
<p>Enabling the FPU before the program entry point if the target is thumbv7em-none-eabihf</p>
</li>
<li>
<p>Provides the following attributes for the no-std programer : </p>
<ul>
<li>#[entry] </li>
<li>#[exception]</li>
<li>#[pre_init] to run code before static variables are initialized</li>
<li>#[interrupt], which allows you to define interrupt handlers. However, since which interrupts are available depends on the microcontroller in use, this attribute should be re-exported and used from a device crate</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="panicking-1"><a class="header" href="#panicking-1">Panicking</a></h1>
<p>Determine how your program reacts when it encounters an unrecoverable error that causes the program to crash.<br />
If you are building a satellite probe, you would want the program to crash differently from how a CLI app crashes... or how a kernel crashes... or how a web app crashes...</p>
<p>Here is a good recommendation chapter : <a href="misc/">Embedded Rust Book (Panicking Chapter)</a></p>
<ul>
<li>You can do conditional compilations using multiple compilation configs : eg use panic_rtt when debuging and use panic_abort when building a release binary. Check out the example below : </li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span>#![no_main]
#![no_std]

<span class="boring">fn main() {
</span>// dev profile: easier to debug panics; can put a breakpoint on `rust_begin_unwind`
#[cfg(debug_assertions)]
use panic_halt as _;

// release profile: minimize the binary size of the application
#[cfg(not(debug_assertions))]
use panic_abort as _;

// ..
<span class="boring">}</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><ul>
<li>learn and imitate : Riscv-rt and Cortex-m-rt</li>
<li>learn and imitate : use cortex_m_semihosting::{debug, hprintln};</li>
<li>learn and fix probe-rs issue with esp32</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>

        <!-- Livereload script (if served using the cli tool) -->
        <script>
            const wsProtocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsAddress = wsProtocol + "//" + location.host + "/" + "__livereload";
            const socket = new WebSocket(wsAddress);
            socket.onmessage = function (event) {
                if (event.data === "reload") {
                    socket.close();
                    location.reload();
                }
            };

            window.onbeforeunload = function() {
                socket.close();
            }
        </script>



        <script>
            window.playground_copyable = true;
        </script>

        <script src="ace.js"></script>
        <script src="editor.js"></script>
        <script src="mode-rust.js"></script>
        <script src="theme-dawn.js"></script>
        <script src="theme-tomorrow_night.js"></script>

        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
